# python.py
# Streamlit app: Dashboard tr·ª±c quan h√≥a K·∫øt lu·∫≠n Thanh tra (KLTT)
# Ch·∫°y: streamlit run python.py
# Y√™u c·∫ßu: pip install streamlit pandas altair openpyxl plotly

import io
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px

st.set_page_config(
    page_title="Dashboard K·∫øt lu·∫≠n Thanh tra (KLTT)",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==============================
# Helpers
# ==============================

@st.cache_data(show_spinner=False)
def load_excel(uploaded_file: io.BytesIO) -> dict:
    xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
    sheets = {s.lower().strip(): s for s in xls.sheet_names}
    out = {}
    for canon, real in sheets.items():
        df = pd.read_excel(xls, real)
        df.columns = [str(c).strip() for c in df.columns]
        out[canon] = df
    return out

def canonicalize_df(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()
    new_cols = {}
    existing_lower = {c.lower(): c for c in df.columns}
    for want, aliases in mapping.items():
        for alias in aliases:
            if alias.lower() in existing_lower:
                new_cols[existing_lower[alias.lower()]] = want
                break
    return df.rename(columns=new_cols)

def coalesce_series_with_raw(series: pd.Series, prefix="RAW"):
    s = series.copy().astype(str)
    null_mask = s.isna() | s.str.strip().eq("") | s.str.lower().eq("nan")
    if null_mask.any():
        raw_index = np.cumsum(null_mask).where(null_mask, 0)
        s.loc[null_mask] = [f"{prefix}{i}" for i in raw_index[null_mask].astype(int)]
    return s

def to_number(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int, float, np.number)): return float(x)
    try:
        return float(str(x).replace(",", "").replace(" ", ""))
    except:
        digits = "".join(ch for ch in str(x) if (ch.isdigit() or ch=='.' or ch=='-'))
        try: return float(digits)
        except: return np.nan

def safe_date(series: pd.Series):
    try: return pd.to_datetime(series, errors="coerce")
    except Exception: return pd.to_datetime(pd.Series([None]*len(series)), errors="coerce")

def format_vnd(n):
    if pd.isna(n): return "‚Äî"
    n = float(n)
    if abs(n) >= 1_000_000_000_000: return f"{n/1_000_000_000_000:.2f} ngh√¨n t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000_000:     return f"{n/1_000_000_000:.2f} t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000:         return f"{n/1_000_000:.2f} tri·ªáu ‚Ç´"
    return f"{n:,.0f} ‚Ç´"

# ==============================
# Theme + CSS
# ==============================

st.markdown("""
<style>
:root { --label-color: #1f6feb; }
[data-testid="stDataFrame"] td, [data-testid="stDataFrame"] th {
  white-space: pre-wrap !important;
  word-break: break-word !important;
}
.info-card { padding: 10px 12px; border: 1px solid #e8e8e8; border-radius: 10px; background: #fff; min-height: 72px; }
.info-card .label { font-size: 12px; color: var(--label-color); font-weight: 700; margin-bottom: 4px; }
.info-card .value { font-size: 15px; line-height: 1.4; white-space: pre-wrap; word-break: break-word; }
.doc-wrap { padding: 10px 14px; border: 1px solid #e6e6e6; border-radius: 12px; background: #fafcff; margin-bottom: 14px; }
.doc-title { font-weight: 700; font-size: 16px; margin-bottom: 8px; color: #0f172a; }
.doc-label { color:#0ea5e9; font-weight:800; }
</style>
""", unsafe_allow_html=True)

def info_card(label, value):
    if value in [None, np.nan, "nan", "None"]:
        value = "‚Äî"
    st.markdown(
        f"""
        <div class="info-card">
          <div class="label"><b>{label}</b></div>
          <div class="value">{value}</div>
        </div>
        """, unsafe_allow_html=True
    )

# ==============================
# Column mappings
# ==============================

COL_MAP = {
    "documents": {
        "doc_id": ["Doc_id","doc_id","DocID","Maso"],
        "issue_date": ["Issue_date","Issues_date","issue_date"],
        "title": ["title","Title"],
        "issuing_authority": ["Issuing_authority","issuing_authority"],
        "inspected_entity_name": ["inspected_entity_name","Inspected_entity_name"],
        "sector": ["sector","Sector"],
        "period_start": ["period_start","Period_start"],
        "period_end": ["period_end","Period_end"],
        "signer_name": ["Signer_name","signer_name"],
        "signer_title": ["Signer_title","signer_title"],
    },
    "overalls": {
        "departments_at_hq_count": ["departments_at_hq_count"],
        "transaction_offices_count": ["transaction_offices_count"],
        "staff_total": ["staff_total"],
        "mobilized_capital_vnd": ["mobilized_capital_vnd"],
        "loans_outstanding_vnd": ["loans_outstanding_vnd"],
        "npl_total_vnd": ["npl_total_vnd"],
        "npl_ratio_percent": ["npl_ratio_percent"],
        "sample_total_files": ["sample_total_files"],
        "sample_outstanding_checked_vnd": ["sample_outstanding_checked_vnd"],

        # B·ªï sung cho ph·∫ßn 2 (bi·ªÉu ƒë·ªì)
        "structure_quality_group1_vnd": ["structure_quality_group1_vnd"],
        "structure_quality_group2_vnd": ["structure_quality_group2_vnd"],
        "structure_quality_group3_vnd": ["structure_quality_group3_vnd"],

        "structure_term_short_vnd": ["structure_term_short_vnd"],
        "structure_term_medium_long_vnd": ["structure_term_medium_long_vnd"],

        "structure_currency_vnd_vnd": ["structure_currency_vnd_vnd"],
        "structure_currency_fx_vnd": ["structure_currency_fx_vnd"],

        "structure_purpose_bds_flexible_vnd": ["structure_purpose_bds_flexible_vnd"],
        "strucuture_purpose_securities_vnd": ["strucuture_purpose_securities_vnd"],  # gi·ªØ nguy√™n ch√≠nh t·∫£ t·ª´ file Excel
        "structure_purpose_consumption_vnd": ["structure_purpose_consumption_vnd"],
        "structure_purpose_trade_vnd": ["structure_purpose_trade_vnd"],
        "structure_purpose_other_vnd": ["structure_purpose_other_vnd"],

        "strucuture_econ_state_vnd": ["strucuture_econ_state_vnd"],
        "strucuture_econ_nonstate_enterprises_vnd": ["strucuture_econ_nonstate_enterprises_vnd"],
        "strucuture_econ_individuals_households_vnd": ["strucuture_econ_individuals_households_vnd"],
    },
    "findings": {
        "category": ["category"],
        "sub_category": ["sub_category"],
        "description": ["description"],
        "legal_reference": ["legal_reference"],
        "quantified_amount": ["quantified_amount"],
        "impacted_accounts": ["impacted_accounts"],
        "root_cause": ["Root_cause","root_cause"],
        "recommendation": ["recommendation"],
    },
    "actions": {
        "action_type": ["action_type"],
        "legal_reference": ["legal_reference"],
        "action_description": ["action_description"],
        "evidence_of_completion": ["evidence_of_completion"],
    }
}

# ==============================
# Sidebar (Upload + Filters)
# ==============================

with st.sidebar:
    st.header("üì§ T·∫£i d·ªØ li·ªáu")
    uploaded = st.file_uploader("Excel (.xlsx): documents, overalls, findings, (actions tu·ª≥ ch·ªçn)", type=["xlsx"])
    st.caption("T√™n sheet & c·ªôt kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng.")

st.title("üõ°Ô∏è Dashboard B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra")

if not uploaded:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

data = load_excel(uploaded)

def get_df(sheet_key):
    raw = data.get(sheet_key)
    mapping = COL_MAP.get(sheet_key, {})
    if raw is None: return pd.DataFrame()
    return canonicalize_df(raw.copy(), mapping)

df_docs = get_df("documents")
df_over = get_df("overalls")
df_find = get_df("findings")
df_act  = get_df("actions")

if df_docs.empty or df_over.empty or df_find.empty:
    st.error("Thi·∫øu m·ªôt trong c√°c sheet b·∫Øt bu·ªôc: documents, overalls, findings.")
    st.stop()

# Dates
for c in ["issue_date","period_start","period_end"]:
    if c in df_docs.columns:
        df_docs[c] = safe_date(df_docs[c])

# Numeric
for c in COL_MAP["overalls"].keys():
    if c in df_over.columns: df_over[c] = df_over[c].apply(to_number)
for c in ["quantified_amount","impacted_accounts"]:
    if c in df_find.columns: df_find[c] = df_find[c].apply(to_number)

# RAW handling
df_find["legal_reference_filter"] = coalesce_series_with_raw(df_find["legal_reference"], prefix="RAW")
df_find["legal_reference_chart"] = df_find["legal_reference_filter"].apply(lambda x: "RAW" if str(x).startswith("RAW") else x)

# Sidebar filter (findings only)
st.sidebar.header("üîé L·ªçc Findings")
all_refs = sorted(df_find["legal_reference_filter"].astype(str).unique().tolist())
selected_refs = st.sidebar.multiselect("Ch·ªçn Legal_reference", options=all_refs, default=all_refs)
f_df = df_find[df_find["legal_reference_filter"].astype(str).isin([str(x) for x in selected_refs])].copy()

st.sidebar.markdown("---")
st.sidebar.metric("üí∏ T·ªïng ti·ªÅn ·∫£nh h∆∞·ªüng (l·ªçc)", format_vnd(f_df["quantified_amount"].sum()))
st.sidebar.metric("üë• T·ªïng h·ªì s∆° ·∫£nh h∆∞·ªüng (l·ªçc)", f"{int(f_df['impacted_accounts'].sum()) if 'impacted_accounts' in f_df.columns and pd.notna(f_df['impacted_accounts'].sum()) else '‚Äî'}")

# ==============================
# Tabs
# ==============================

tab_docs, tab_over, tab_find, tab_act = st.tabs(["üìù Documents","üìä Overalls","üö® Findings","‚úÖ Actions"])

# ---- Documents (no dropdown; render all docs) ----
with tab_docs:
    st.header("B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra (Metadata)")
    st.markdown("---")
    if len(df_docs) == 0:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu documents.")
    else:
        for _, row in df_docs.reset_index(drop=True).iterrows():
            st.markdown(f'<div class="doc-wrap"><div class="doc-title">üìù B√°o c√°o k·∫øt lu·∫≠n thanh tra ‚Äî {str(row.get("doc_id","‚Äî"))}</div>', unsafe_allow_html=True)
            c1, c2, c3, c4 = st.columns(4)
            with c1:
                info_card("<span class='doc-label'>M√£ s·ªë KLTT (Doc_id)</span>", str(row.get("doc_id","‚Äî")))
                info_card("<span class='doc-label'>ƒê∆°n v·ªã ph√°t h√†nh</span>", str(row.get("issuing_authority","‚Äî")))
                info_card("<span class='doc-label'>Ng∆∞·ªùi ki·ªÉm so√°t</span>", str(row.get("signer_name","‚Äî")))
            with c2:
                d = row.get("issue_date", pd.NaT)
                info_card("<span class='doc-label'>Ng√†y ph√°t h√†nh</span>", d.strftime("%d/%m/%Y") if pd.notna(d) else "‚Äî")
                info_card("<span class='doc-label'>ƒê∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm tra</span>", str(row.get("inspected_entity_name","‚Äî")))
                info_card("<span class='doc-label'>Ch·ª©c v·ª•</span>", str(row.get("signer_title","‚Äî")))
            with c3:
                info_card("<span class='doc-label'>Title</span>", str(row.get("title","‚Äî")))
                info_card("<span class='doc-label'>Lƒ©nh v·ª±c</span>", str(row.get("sector","‚Äî")))
            with c4:
                ps = row.get("period_start", pd.NaT); pe = row.get("period_end", pd.NaT)
                info_card("<span class='doc-label'>Th·ªùi gian b·∫Øt ƒë·∫ßu</span>", ps.strftime("%d/%m/%Y") if pd.notna(ps) else "‚Äî")
                info_card("<span class='doc-label'>Th·ªùi gian k·∫øt th√∫c</span>", pe.strftime("%d/%m/%Y") if pd.notna(pe) else "‚Äî")
            st.markdown("</div>", unsafe_allow_html=True)

# ---- Overalls ----
with tab_over:
    st.header("Th√¥ng Tin T·ªïng Quan")
    st.markdown("---")
    over_row = df_over.iloc[-1] if len(df_over) else pd.Series({})

    # KPIs s∆° l∆∞·ª£c
    k1,k2,k3,k4,k5 = st.columns(5)
    with k1:
        st.metric("T·ªïng nh√¢n s·ª±", f"{int(over_row.get('staff_total', np.nan)) if pd.notna(over_row.get('staff_total', np.nan)) else '‚Äî'}")
        st.metric("M·∫´u ki·ªÉm tra", f"{int(over_row.get('sample_total_files', np.nan)) if pd.notna(over_row.get('sample_total_files', np.nan)) else '‚Äî'}")
    with k2:
        st.metric("Ph√≤ng nghi·ªáp v·ª• (HQ)", f"{int(over_row.get('departments_at_hq_count', np.nan)) if pd.notna(over_row.get('departments_at_hq_count', np.nan)) else '‚Äî'}")
        st.metric("Ph√≤ng giao d·ªãch", f"{int(over_row.get('transaction_offices_count', np.nan)) if pd.notna(over_row.get('transaction_offices_count', np.nan)) else '‚Äî'}")
    with k3:
        st.metric("Ngu·ªìn v·ªën g·∫ßn nh·∫•t", format_vnd(over_row.get("mobilized_capital_vnd", np.nan)))
    with k4:
        st.metric("D∆∞ n·ª£ g·∫ßn nh·∫•t", format_vnd(over_row.get("loans_outstanding_vnd", np.nan)))
    with k5:
        st.metric("N·ª£ x·∫•u (nh√≥m 3-5)", format_vnd(over_row.get("npl_total_vnd", np.nan)))
        st.metric("T·ª∑ l·ªá NPL / D∆∞ n·ª£", f"{over_row.get('npl_ratio_percent', np.nan):.2f}%" if pd.notna(over_row.get('npl_ratio_percent', np.nan)) else "‚Äî")
        st.metric("T·ªïng d∆∞ n·ª£ ƒë√£ ki·ªÉm tra", format_vnd(over_row.get("sample_outstanding_checked_vnd", np.nan)))

    # ===== BI·ªÇU ƒê·ªí =====
    st.markdown("---")

    # 1) Line chart: ch·∫•t l∆∞·ª£ng nh√≥m 1-3 theo th·ªùi gian (n·∫øu c√≥ nhi·ªÅu b·∫£n ghi)
    st.subheader("Xu h∆∞·ªõng ch·∫•t l∆∞·ª£ng t√≠n d·ª•ng (Nh√≥m 1-3)")
    q_cols = ["structure_quality_group1_vnd","structure_quality_group2_vnd","structure_quality_group3_vnd"]
    available_q = [c for c in q_cols if c in df_over.columns]
    if available_q:
        dfq = df_over[available_q].copy()
        # Tr·ª•c th·ªùi gian: ∆∞u ti√™n issue_date/period_end n·∫øu t·ªìn t·∫°i, n·∫øu kh√¥ng d√πng index th·ª© t·ª±
        time_col = None
        for tcol in ["issue_date","period_end","period_start"]:
            if tcol in df_docs.columns:
                time_col = tcol
                break
        if time_col and not df_docs.empty:
            # g·∫Øn th·ªùi ƒëi·ªÉm c·ªßa documents g·∫ßn nh·∫•t chi·ªÅu d√†i df_over, fallback index
            x_axis = pd.Series(range(1, len(df_over)+1), name="K·ª≥")
        else:
            x_axis = pd.Series(range(1, len(df_over)+1), name="K·ª≥")
        dfq.insert(0, "K·ª≥", x_axis)
        dfm = dfq.melt(id_vars="K·ª≥", var_name="Nh√≥m", value_name="Gi√° tr·ªã")
        dfm["Gi√° tr·ªã"] = dfm["Gi√° tr·ªã"].apply(to_number)
        fig_q = px.line(dfm, x="K·ª≥", y="Gi√° tr·ªã", color="Nh√≥m", markers=True,
                        labels={"Gi√° tr·ªã":"S·ªë ti·ªÅn (VND)"})
        fig_q.update_layout(height=360, yaxis_title="VND", xaxis_title="K·ª≥")
        st.plotly_chart(fig_q, use_container_width=True)
    else:
        st.info("Kh√¥ng c√≥ c·ªôt structure_quality_group1/2/3_vnd ƒë·ªÉ v·∫Ω xu h∆∞·ªõng.")

    # 2) Bar: c∆° c·∫•u k·ª≥ h·∫°n
    st.subheader("C∆° c·∫•u theo k·ª≥ h·∫°n")
    term_items = [
        ("D∆∞ n·ª£ ng·∫Øn h·∫°n", "structure_term_short_vnd"),
        ("D∆∞ n·ª£ trung & d√†i h·∫°n", "structure_term_medium_long_vnd"),
    ]
    term_data = [{"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": over_row.get(c, np.nan)} for n, c in term_items if c in df_over.columns]
    if term_data:
        dft = pd.DataFrame(term_data)
        dft["Gi√° tr·ªã"] = dft["Gi√° tr·ªã"].apply(to_number)
        fig_t = px.bar(dft, x="Ch·ªâ ti√™u", y="Gi√° tr·ªã", text=dft["Gi√° tr·ªã"].apply(lambda v: format_vnd(v)))
        fig_t.update_traces(textposition="outside")
        fig_t.update_layout(height=320, yaxis_title="VND", xaxis_title="")
        st.plotly_chart(fig_t, use_container_width=True)

    # 3) Bar: c∆° c·∫•u ti·ªÅn t·ªá
    st.subheader("C∆° c·∫•u theo ti·ªÅn t·ªá")
    cur_items = [
        ("D∆∞ n·ª£ b·∫±ng VND", "structure_currency_vnd_vnd"),
        ("D∆∞ n·ª£ quy ƒë·ªïi ngo·∫°i t·ªá", "structure_currency_fx_vnd"),
    ]
    cur_data = [{"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": over_row.get(c, np.nan)} for n, c in cur_items if c in df_over.columns]
    if cur_data:
        dfc = pd.DataFrame(cur_data)
        dfc["Gi√° tr·ªã"] = dfc["Gi√° tr·ªã"].apply(to_number)
        fig_c = px.bar(dfc, x="Ch·ªâ ti√™u", y="Gi√° tr·ªã", text=dfc["Gi√° tr·ªã"].apply(lambda v: format_vnd(v)))
        fig_c.update_traces(textposition="outside")
        fig_c.update_layout(height=320, yaxis_title="VND", xaxis_title="")
        st.plotly_chart(fig_c, use_container_width=True)

    # 4) Bar: c∆° c·∫•u m·ª•c ƒë√≠ch
    st.subheader("C∆° c·∫•u theo m·ª•c ƒë√≠ch vay")
    pur_items = [
        ("BƒêS / linh ho·∫°t", "structure_purpose_bds_flexible_vnd"),
        ("Ch·ª©ng kho√°n", "strucuture_purpose_securities_vnd"),
        ("Ti√™u d√πng", "structure_purpose_consumption_vnd"),
        ("Th∆∞∆°ng m·∫°i", "structure_purpose_trade_vnd"),
        ("M·ª•c ƒë√≠ch kh√°c", "structure_purpose_other_vnd"),
    ]
    pur_data = [{"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": over_row.get(c, np.nan)} for n, c in pur_items if c in df_over.columns]
    if pur_data:
        dfp = pd.DataFrame(pur_data)
        dfp["Gi√° tr·ªã"] = dfp["Gi√° tr·ªã"].apply(to_number)
        fig_p = px.bar(dfp, x="Ch·ªâ ti√™u", y="Gi√° tr·ªã", text=dfp["Gi√° tr·ªã"].apply(lambda v: format_vnd(v)))
        fig_p.update_traces(textposition="outside")
        fig_p.update_layout(height=360, yaxis_title="VND", xaxis_title="")
        st.plotly_chart(fig_p, use_container_width=True)

    # 5) Bar: c∆° c·∫•u theo th√†nh ph·∫ßn kinh t·∫ø
    st.subheader("C∆° c·∫•u theo th√†nh ph·∫ßn kinh t·∫ø")
    eco_items = [
        ("DN Nh√† n∆∞·ªõc", "strucuture_econ_state_vnd"),
        ("DN ngo√†i QD", "strucuture_econ_nonstate_enterprises_vnd"),
        ("C√° nh√¢n/H·ªô gia ƒë√¨nh", "strucuture_econ_individuals_households_vnd"),
    ]
    eco_data = [{"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": over_row.get(c, np.nan)} for n, c in eco_items if c in df_over.columns]
    if eco_data:
        dfe = pd.DataFrame(eco_data)
        dfe["Gi√° tr·ªã"] = dfe["Gi√° tr·ªã"].apply(to_number)
        fig_e = px.bar(dfe, x="Ch·ªâ ti√™u", y="Gi√° tr·ªã", text=dfe["Gi√° tr·ªã"].apply(lambda v: format_vnd(v)))
        fig_e.update_traces(textposition="outside")
        fig_e.update_layout(height=360, yaxis_title="VND", xaxis_title="")
        st.plotly_chart(fig_e, use_container_width=True)

# ---- Findings ----
with tab_find:
    st.header("Ph√°t hi·ªán & Nguy√™n nh√¢n (Findings)")
    st.subheader(f"ƒêang l·ªçc theo: {len(selected_refs)}/{len(all_refs)} legal_reference")
    st.markdown("---")
    if f_df.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu theo b·ªô l·ªçc hi·ªán t·∫°i.")
    else:
        col1, col2 = st.columns(2)
        with col1:
            cat_count = f_df["category"].value_counts().reset_index()
            cat_count.columns = ["Category","Count"]
            fig1 = px.bar(cat_count, x="Category", y="Count", text="Count", color="Category",
                          title="S·ªë l·∫ßn xu·∫•t hi·ªán theo Category")
            fig1.update_traces(textposition="outside")
            fig1.update_layout(height=380, xaxis_title="", yaxis_title="S·ªë l·∫ßn")
            st.plotly_chart(fig1, use_container_width=True)
        with col2:
            cat_sub = f_df.groupby(["category","sub_category"]).size().reset_index(name="Count")
            fig2 = px.bar(cat_sub, x="category", y="Count", color="sub_category",
                          title="Category √ó Sub_category (s·ªë l·∫ßn)", barmode="group",
                          labels={"category":"Category","sub_category":"Sub_category","Count":"S·ªë l·∫ßn"})
            fig2.update_layout(height=380)
            st.plotly_chart(fig2, use_container_width=True)

        st.markdown("---")
        st.subheader("Xu h∆∞·ªõng theo Legal_reference (g·ªôp RAW1/RAW2/RAW3 ‚Üí RAW)")
        legal_count = f_df["legal_reference_chart"].value_counts().reset_index()
        legal_count.columns = ["Legal_reference","Count"]
        fig3 = px.line(legal_count, x="Legal_reference", y="Count", markers=True,
                       title="S·ªë l·∫ßn xu·∫•t hi·ªán theo Legal_reference")
        st.plotly_chart(fig3, use_container_width=True)
        st.info("RAW = lu·∫≠t/quy ƒë·ªãnh kh√¥ng ƒë∆∞·ª£c nh·∫Øc t·ªõi; √¥ tr·ªëng ƒë√£ g√°n RAW1, RAW2‚Ä¶ v√† g·ªôp th√†nh RAW cho bi·ªÉu ƒë·ªì.")

        st.markdown("---")
        st.subheader("T·∫ßn su·∫•t t·ª´ng Legal_reference (kh√¥ng g·ªôp ph·ª• l·ª•c/ƒëi·ªÉm kho·∫£n)")
        freq_tbl = f_df["legal_reference_filter"].value_counts().reset_index()
        freq_tbl.columns = ["Legal_reference","S·ªë l·∫ßn"]
        st.dataframe(freq_tbl, use_container_width=True, height=320)

        st.markdown("---")
        st.subheader("Chi ti·∫øt theo t·ª´ng Sub_category")
        order_sub = f_df["sub_category"].value_counts().index.tolist()
        for sub in order_sub:
            st.markdown(f"#### üîπ {sub}")
            sub_df = f_df[f_df["sub_category"]==sub].copy()
            # Gi·ªØ RAW1/RAW2/RAW3 nguy√™n vƒÉn, kh√¥ng t·∫°o c·ªôt 'none' v√† KH√îNG hi·ªÉn th·ªã recommendation ·ªü ƒë√¢y
            sub_df["legal_reference"] = sub_df["legal_reference_filter"]
            cols_show = [c for c in ["description","legal_reference","quantified_amount","impacted_accounts","root_cause"] if c in sub_df.columns]
            sub_df = sub_df[cols_show]
            if "quantified_amount" in sub_df.columns:
                sub_df["quantified_amount"] = sub_df["quantified_amount"].apply(format_vnd)
            if "impacted_accounts" in sub_df.columns:
                sub_df["impacted_accounts"] = sub_df["impacted_accounts"].apply(lambda x: f"{int(x):,}" if pd.notna(x) else "‚Äî")
            rename = {
                "description":"M√¥ t·∫£",
                "legal_reference":"ƒêi·ªÅu lu·∫≠t/Quy ƒë·ªãnh",
                "quantified_amount":"S·ªë ti·ªÅn ·∫£nh h∆∞·ªüng",
                "impacted_accounts":"S·ªë KH/H·ªì s∆°",
                "root_cause":"Nguy√™n nh√¢n g·ªëc"
            }
            st.dataframe(sub_df.rename(columns=rename), use_container_width=True)

        st.markdown("---")
        st.subheader("Ph√¢n t√≠ch theo b·ªô lu·∫≠t")
        tmp = f_df.copy()
        tmp["legal_reference"] = tmp["legal_reference_filter"]
        cols = ["legal_reference"]
        if "root_cause" in tmp.columns: cols.append("root_cause")
        if "recommendation" in tmp.columns: cols.append("recommendation")
        law_tbl = tmp[cols].drop_duplicates().reset_index(drop=True)
        law_tbl = law_tbl.rename(columns={
            "legal_reference":"Legal_reference",
            "root_cause":"Root_cause",
            "recommendation":"Recommendation"
        })
        # B·ªè c√°c c·ªôt t·ªïng h·ª£p s·ªë v·ª•/h·ªì s∆°/ti·ªÅn theo y√™u c·∫ßu (kh√¥ng t√≠nh t·ªïng)
        st.dataframe(law_tbl, use_container_width=True)

# ---- Actions (show ALL rows, no filtering by findings) ----
with tab_act:
    st.header("Bi·ªán ph√°p kh·∫Øc ph·ª•c (Actions)")
    st.markdown("---")
    if df_act is None or df_act.empty:
        st.info("Kh√¥ng c√≥ sheet actions ho·∫∑c thi·∫øu c·ªôt. C·∫ßn: action_type, legal_reference, action_description, evidence_of_completion.")
    else:
        df_act_full = df_act.copy()
        df_act_full["Legal_reference"] = coalesce_series_with_raw(df_act_full["legal_reference"], prefix="RAW")
        # Chart: ph√¢n lo·∫°i r√µ t√≠nh ch·∫•t
        if "action_type" in df_act_full.columns:
            act_count = df_act_full["action_type"].value_counts().reset_index()
            act_count.columns = ["Action_type","Count"]
            fig = px.pie(act_count, values="Count", names="Action_type", title="Ph√¢n lo·∫°i t√≠nh ch·∫•t bi·ªán ph√°p", hole=.35)
            fig.update_traces(textinfo="percent+label")
            st.plotly_chart(fig, use_container_width=True)
        st.markdown("---")
        # Table (hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß m·ªçi d√≤ng)
        cols = [c for c in ["Legal_reference","action_type","action_description","evidence_of_completion"] if c in df_act_full.columns or c=="Legal_reference"]
        rename = {
            "action_type":"T√≠nh ch·∫•t bi·ªán ph√°p",
            "action_description":"N·ªôi dung c√¥ng vi·ªác ph·∫£i l√†m",
            "evidence_of_completion":"C√¥ng vi·ªác chi ti·∫øt / Minh ch·ª©ng"
        }
        st.dataframe(df_act_full[cols].rename(columns=rename), use_container_width=True, height=500)
        st.caption(f"ƒêang hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß {len(df_act_full)} d√≤ng actions.")

st.caption("¬© KLTT Dashboard ‚Ä¢ Streamlit ‚Ä¢ Altair ‚Ä¢ Plotly")
