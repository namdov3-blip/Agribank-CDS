
# python.py
# Streamlit app: Dashboard tr·ª±c quan h√≥a K·∫øt lu·∫≠n Thanh tra (KLTT)
# Ch·∫°y: streamlit run python.py
# Y√™u c·∫ßu: pip install streamlit pandas altair openpyxl plotly

import io
from io import BytesIO
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(
    page_title="Dashboard K·∫øt lu·∫≠n Thanh tra (KLTT)",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==============================
# 1) HELPERS & UTILITIES
# ==============================

@st.cache_data(show_spinner=False)
def load_excel(uploaded_file: io.BytesIO) -> dict:
    """ƒê·ªçc t·∫•t c·∫£ sheet, chu·∫©n h√≥a t√™n sheet (lower, strip), strip t√™n c·ªôt."""
    xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
    sheets = {s.lower().strip(): s for s in xls.sheet_names}
    dfs = {}
    for canon, real in sheets.items():
        df = pd.read_excel(xls, real)
        df.columns = [str(c).strip() for c in df.columns]
        dfs[canon] = df
    return dfs

def canonicalize_df(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:
    """√Ånh x·∫° t√™n c·ªôt (case-insensitive) sang t√™n chu·∫©n ƒë√£ ƒë·ªãnh nghƒ©a trong mapping."""
    if df is None or df.empty:
        return pd.DataFrame()
    new_cols = {}
    existing_lower = {c.lower(): c for c in df.columns}
    for want, aliases in mapping.items():
        for alias in aliases:
            if alias.lower() in existing_lower:
                new_cols[existing_lower[alias.lower()]] = want
                break
    return df.rename(columns=new_cols)

def coalesce_series_with_raw(series: pd.Series, prefix="RAW"):
    """Thay th·∫ø √¥ tr·ªëng/NaN th√†nh RAW1, RAW2... ƒë·ªÉ l·ªçc chi ti·∫øt."""
    s = series.copy()
    s = s.astype(str)
    null_mask = s.isna() | s.str.strip().eq("") | s.str.lower().eq("nan")
    if null_mask.any():
        raw_index = np.cumsum(null_mask).where(null_mask, 0)
        s.loc[null_mask] = [f"{prefix}{i}" for i in raw_index[null_mask].astype(int)]
    return s

def to_number(x):
    if pd.isna(x):
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    try:
        return float(str(x).replace(",", "").replace(" ", ""))
    except:
        digits = "".join(ch for ch in str(x) if (ch.isdigit() or ch=='.' or ch=='-'))
        try:
            return float(digits)
        except:
            return np.nan

def safe_date(series: pd.Series):
    try:
        return pd.to_datetime(series, errors="coerce")
    except Exception:
        return pd.to_datetime(pd.Series([None]*len(series)), errors="coerce")

def format_vnd(n):
    if pd.isna(n):
        return "‚Äî"
    n = float(n)
    if abs(n) >= 1_000_000_000_000:
        return f"{n/1_000_000_000_000:.2f} ngh√¨n t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000_000:
        return f"{n/1_000_000_000:.2f} t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000:
        return f"{n/1_000_000:.2f} tri·ªáu ‚Ç´"
    return f"{n:,.0f} ‚Ç´"

# CSS: wrap text & style
st.markdown("""
<style>
[data-testid="stDataFrame"] td, [data-testid="stDataFrame"] th {
  white-space: pre-wrap !important;
  word-break: break-word !important;
}
.info-card { padding: 10px 12px; border: 1px solid #e8e8e8; border-radius: 10px; background: #fff; min-height: 72px; }
.info-card .label { font-size: 12px; color: #666; margin-bottom: 2px; }
.info-card .value { font-size: 15px; line-height: 1.35; white-space: pre-wrap; word-break: break-word; }
</style>
""", unsafe_allow_html=True)

def info_card(label, value):
    st.markdown(
        f"""
        <div class="info-card">
          <div class="label">{label}</div>
          <div class="value">{value if value not in [None, np.nan, 'nan'] else '‚Äî'}</div>
        </div>
        """, unsafe_allow_html=True
    )

# ==============================
# 2) COLUMN MAPPINGS
# ==============================
COL_MAP = {
    "documents": {
        "doc_id": ["Doc_id","doc_id","DocID"],
        "issue_date": ["Issue_date","Issues_date","issue_date"],
        "title": ["title","Title"],
        "issuing_authority": ["Issuing_authority","issuing_authority"],
        "inspected_entity_name": ["inspected_entity_name","Inspected_entity_name"],
        "sector": ["sector","Sector"],
        "period_start": ["period_start","Period_start"],
        "period_end": ["period_end","Period_end"],
        "signer_name": ["Signer_name","signer_name"],
        "signer_title": ["Signer_title","signer_title"],
    },
    "overalls": {
        "departments_at_hq_count": ["departments_at_hq_count"],
        "transaction_offices_count": ["transaction_offices_count"],
        "staff_total": ["staff_total"],
        "mobilized_capital_vnd": ["mobilized_capital_vnd"],
        "loans_outstanding_vnd": ["loans_outstanding_vnd"],
        "npl_total_vnd": ["npl_total_vnd"],
        "npl_ratio_percent": ["npl_ratio_percent"],
        "sample_total_files": ["sample_total_files"],
        "sample_outstanding_checked_vnd": ["sample_outstanding_checked_vnd"],
    },
    "findings": {
        "category": ["category"],
        "sub_category": ["sub_category"],
        "description": ["description"],
        "legal_reference": ["legal_reference"],
        "quantified_amount": ["quantified_amount"],
        "impacted_accounts": ["impacted_accounts"],
        "root_cause": ["Root_cause","root_cause"],
        "recommendation": ["recommendation"],
    },
    "actions": {
        "action_type": ["action_type"],
        "legal_reference": ["legal_reference"],
        "action_description": ["action_description"],
        "evidence_of_completion": ["evidence_of_completion"],
    }
}

# ==============================
# 3) SIDEBAR (Upload & Filters)
# ==============================
with st.sidebar:
    st.header("üì§ T·∫£i d·ªØ li·ªáu")
    uploaded = st.file_uploader("Excel (.xlsx): documents, overalls, findings, (actions tu·ª≥ ch·ªçn)", type=["xlsx"])
    st.caption("App t·ª± nh·∫≠n alias t√™n c·ªôt, kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng.")

st.title("üõ°Ô∏è Dashboard B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra")

if not uploaded:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

data = load_excel(uploaded)

def get_df(sheet_key):
    raw = data.get(sheet_key)
    mapping = COL_MAP.get(sheet_key, {})
    if raw is None:
        return pd.DataFrame()
    return canonicalize_df(raw.copy(), mapping)

df_docs = get_df("documents")
df_over = get_df("overalls")
df_find = get_df("findings")
df_act  = get_df("actions")

if df_docs.empty or df_over.empty or df_find.empty:
    st.error("Thi·∫øu m·ªôt trong c√°c sheet b·∫Øt bu·ªôc: documents, overalls, findings.")
    st.stop()

for c in ["issue_date","period_start","period_end"]:
    if c in df_docs.columns:
        df_docs[c] = safe_date(df_docs[c])

for c in COL_MAP["overalls"].keys():
    if c in df_over.columns:
        df_over[c] = df_over[c].apply(to_number)

for c in ["quantified_amount","impacted_accounts"]:
    if c in df_find.columns:
        df_find[c] = df_find[c].apply(to_number)

df_find["legal_reference_filter"] = coalesce_series_with_raw(df_find["legal_reference"], prefix="RAW")
df_find["legal_reference_chart"] = df_find["legal_reference_filter"].apply(lambda x: "RAW" if str(x).startswith("RAW") else x)

st.sidebar.header("üîé L·ªçc Findings")
all_refs = sorted(df_find["legal_reference_filter"].astype(str).unique().tolist())
selected_refs = st.sidebar.multiselect("Ch·ªçn Legal_reference", options=all_refs, default=all_refs)
f_df = df_find[df_find["legal_reference_filter"].astype(str).isin([str(x) for x in selected_refs])].copy()

st.sidebar.markdown("---")
st.sidebar.metric("üí∏ T·ªïng ti·ªÅn ·∫£nh h∆∞·ªüng (l·ªçc)", format_vnd(f_df["quantified_amount"].sum()))
st.sidebar.metric("üë• T·ªïng h·ªì s∆° ·∫£nh h∆∞·ªüng (l·ªçc)", f"{int(f_df['impacted_accounts'].sum()) if 'impacted_accounts' in f_df.columns and pd.notna(f_df['impacted_accounts'].sum()) else '‚Äî'}")

# ==============================
# 4) TABS
# ==============================
tab_docs, tab_over, tab_find, tab_act = st.tabs(["üìù Documents","üìä Overalls","üö® Findings","‚úÖ Actions"])

with tab_docs:
    st.header("B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra (Metadata)")
    st.markdown("---")
    # Ch·ªçn theo doc_id ho·∫∑c title
    select_col = "doc_id" if "doc_id" in df_docs.columns else ("title" if "title" in df_docs.columns else None)
    options = df_docs[select_col].astype(str).tolist() if select_col else []
    chosen = st.selectbox("Ch·ªçn KLTT", options, index=0 if options else None)
    row = df_docs[df_docs[select_col].astype(str)==str(chosen)].iloc[0] if options else None

    c1,c2,c3,c4 = st.columns(4)
    if row is not None:
        with c1:
            info_card("M√£ s·ªë KLTT (Doc_id)", str(row.get("doc_id","‚Äî")))
            info_card("ƒê∆°n v·ªã ph√°t h√†nh", str(row.get("issuing_authority","‚Äî")))
            info_card("Ng∆∞·ªùi ki·ªÉm so√°t", str(row.get("signer_name","‚Äî")))
        with c2:
            d = row.get("issue_date", pd.NaT)
            info_card("Ng√†y ph√°t h√†nh", d.strftime("%d/%m/%Y") if pd.notna(d) else "‚Äî")
            info_card("ƒê∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm tra", str(row.get("inspected_entity_name","‚Äî")))
            info_card("Ch·ª©c v·ª•", str(row.get("signer_title","‚Äî")))
        with c3:
            info_card("Title", str(row.get("title","‚Äî")))
            info_card("Lƒ©nh v·ª±c", str(row.get("sector","‚Äî")))
        with c4:
            ps = row.get("period_start", pd.NaT); pe = row.get("period_end", pd.NaT)
            info_card("Th·ªùi gian b·∫Øt ƒë·∫ßu", ps.strftime("%d/%m/%Y") if pd.notna(ps) else "‚Äî")
            info_card("Th·ªùi gian k·∫øt th√∫c", pe.strftime("%d/%m/%Y") if pd.notna(pe) else "‚Äî")

with tab_over:
    st.header("Th√¥ng Tin T·ªïng Quan")
    st.markdown("---")
    over_row = df_over.iloc[-1] if len(df_over) else pd.Series({})

    k1,k2,k3,k4,k5 = st.columns(5)
    with k1:
        st.metric("T·ªïng nh√¢n s·ª±", f"{int(over_row.get('staff_total', np.nan)) if pd.notna(over_row.get('staff_total', np.nan)) else '‚Äî'}")
        st.metric("M·∫´u ki·ªÉm tra", f"{int(over_row.get('sample_total_files', np.nan)) if pd.notna(over_row.get('sample_total_files', np.nan)) else '‚Äî'}")
    with k2:
        st.metric("Ph√≤ng nghi·ªáp v·ª• (HQ)", f"{int(over_row.get('departments_at_hq_count', np.nan)) if pd.notna(over_row.get('departments_at_hq_count', np.nan)) else '‚Äî'}")
        st.metric("Ph√≤ng giao d·ªãch", f"{int(over_row.get('transaction_offices_count', np.nan)) if pd.notna(over_row.get('transaction_offices_count', np.nan)) else '‚Äî'}")
    with k3:
        st.metric("Ngu·ªìn v·ªën g·∫ßn nh·∫•t", format_vnd(over_row.get("mobilized_capital_vnd", np.nan)))
    with k4:
        st.metric("D∆∞ n·ª£ g·∫ßn nh·∫•t", format_vnd(over_row.get("loans_outstanding_vnd", np.nan)))
    with k5:
        st.metric("N·ª£ x·∫•u g·∫ßn nh·∫•t", format_vnd(over_row.get("npl_total_vnd", np.nan)))
        st.metric("T·ª∑ l·ªá NPL / D∆∞ n·ª£", f"{over_row.get('npl_ratio_percent', np.nan):.2f}%" if pd.notna(over_row.get('npl_ratio_percent', np.nan)) else "‚Äî")
        st.metric("T·ªïng d∆∞ n·ª£ ƒë√£ ki·ªÉm tra", format_vnd(over_row.get("sample_outstanding_checked_vnd", np.nan)))

with tab_find:
    st.header("Ph√°t hi·ªán & Nguy√™n nh√¢n (Findings)")
    st.subheader(f"ƒêang l·ªçc theo: {len(selected_refs)}/{len(all_refs)} legal_reference")
    st.markdown("---")
    if f_df.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu theo b·ªô l·ªçc hi·ªán t·∫°i.")
    else:
        col1,col2 = st.columns(2)
        with col1:
            cat_count = f_df["category"].value_counts().reset_index()
            cat_count.columns = ["Category","Count"]
            fig1 = px.bar(cat_count, x="Category", y="Count", text="Count", color="Category",
                          title="S·ªë l·∫ßn xu·∫•t hi·ªán theo Category")
            fig1.update_traces(textposition="outside")
            fig1.update_layout(height=380, xaxis_title="", yaxis_title="S·ªë l·∫ßn")
            st.plotly_chart(fig1, use_container_width=True)
        with col2:
            cat_sub = f_df.groupby(["category","sub_category"]).size().reset_index(name="Count")
            fig2 = px.bar(cat_sub, x="category", y="Count", color="sub_category",
                          title="Category √ó Sub_category (s·ªë l·∫ßn)", barmode="group",
                          labels={"category":"Category","sub_category":"Sub_category","Count":"S·ªë l·∫ßn"})
            fig2.update_layout(height=380)
            st.plotly_chart(fig2, use_container_width=True)

        st.markdown("---")
        st.subheader("Line chart: Legal_reference (g·ªôp RAWx‚ÜíRAW)")
        legal_count = f_df["legal_reference_chart"].value_counts().reset_index()
        legal_count.columns = ["Legal_reference","Count"]
        fig3 = px.line(legal_count, x="Legal_reference", y="Count", markers=True,
                       title="S·ªë l·∫ßn xu·∫•t hi·ªán theo Legal_reference (g·ªôp RAWx‚ÜíRAW)")
        st.plotly_chart(fig3, use_container_width=True)
        st.info("RAW = lu·∫≠t/quy ƒë·ªãnh kh√¥ng ƒë∆∞·ª£c nh·∫Øc r√µ; √¥ tr·ªëng ƒë√£ g√°n RAW1, RAW2‚Ä¶ v√† g·ªôp th√†nh RAW trong bi·ªÉu ƒë·ªì.")

        st.markdown("---")
        st.subheader("T·∫ßn su·∫•t t·ª´ng Legal_reference (kh√¥ng g·ªôp ph·ª• l·ª•c)")
        freq_tbl = f_df["legal_reference_filter"].value_counts().reset_index()
        freq_tbl.columns = ["Legal_reference","S·ªë l·∫ßn"]
        st.dataframe(freq_tbl, use_container_width=True, height=320)

        st.markdown("---")
        st.subheader("Chi ti·∫øt theo Sub_category")
        order_sub = f_df["sub_category"].value_counts().index.tolist()
        for sub in order_sub:
            st.markdown(f"#### üîπ {sub}")
            cols_show = [c for c in ["description","legal_reference","legal_reference_filter","quantified_amount","impacted_accounts","root_cause","recommendation"] if c in f_df.columns]
            sub_df = f_df[f_df["sub_category"]==sub][cols_show].copy()
            if "quantified_amount" in sub_df.columns:
                sub_df["quantified_amount"] = sub_df["quantified_amount"].apply(format_vnd)
            if "impacted_accounts" in sub_df.columns:
                sub_df["impacted_accounts"] = sub_df["impacted_accounts"].apply(lambda x: f"{int(x):,}" if pd.notna(x) else "‚Äî")
            rename = {
                "description":"M√¥ t·∫£",
                "legal_reference":"ƒêi·ªÅu lu·∫≠t (g·ªëc)",
                "legal_reference_filter":"ƒêi·ªÅu lu·∫≠t (l·ªçc RAWx)",
                "quantified_amount":"S·ªë ti·ªÅn ·∫£nh h∆∞·ªüng",
                "impacted_accounts":"S·ªë KH/H·ªì s∆°",
                "root_cause":"Nguy√™n nh√¢n g·ªëc",
                "recommendation":"Khuy·∫øn ngh·ªã"
            }
            st.dataframe(sub_df.rename(columns=rename), use_container_width=True)

        st.markdown("---")
        st.subheader("T·ªïng h·ª£p Root_cause & Recommendation theo Legal_reference")
        group_cols = ["legal_reference"]
        if "root_cause" in f_df.columns: group_cols.append("root_cause")
        if "recommendation" in f_df.columns: group_cols.append("recommendation")
        agg = {"description":"count"}
        if "quantified_amount" in f_df.columns: agg["quantified_amount"]="sum"
        if "impacted_accounts" in f_df.columns: agg["impacted_accounts"]="sum"
        root_tbl = f_df.groupby(group_cols, dropna=False).agg(agg).reset_index().rename(columns={"description":"S·ªë v·ª•"})
        if "quantified_amount" in root_tbl.columns:
            root_tbl["T·ªïng ti·ªÅn ·∫£nh h∆∞·ªüng"] = root_tbl["quantified_amount"].apply(format_vnd)
            root_tbl = root_tbl.drop(columns=["quantified_amount"])
        if "impacted_accounts" in root_tbl.columns:
            root_tbl["T·ªïng h·ªì s∆° ·∫£nh h∆∞·ªüng"] = root_tbl["impacted_accounts"].apply(lambda x: f"{int(x):,}" if pd.notna(x) else "‚Äî")
            root_tbl = root_tbl.drop(columns=["impacted_accounts"])
        show_cols = [c for c in ["legal_reference","root_cause","recommendation","S·ªë v·ª•","T·ªïng h·ªì s∆° ·∫£nh h∆∞·ªüng","T·ªïng ti·ªÅn ·∫£nh h∆∞·ªüng"] if c in root_tbl.columns]
        st.dataframe(root_tbl[show_cols], use_container_width=True)

with tab_act:
    st.header("Bi·ªán ph√°p kh·∫Øc ph·ª•c (Actions)")
    st.markdown("---")
    if df_act is None or df_act.empty:
        st.info("Kh√¥ng c√≥ sheet actions ho·∫∑c thi·∫øu c·ªôt. C·∫ßn: action_type, legal_reference, action_description, evidence_of_completion.")
    else:
        df_act["legal_reference_filter"] = coalesce_series_with_raw(df_act["legal_reference"], prefix="RAW")
        a_df = df_act[df_act["legal_reference_filter"].astype(str).isin([str(x) for x in selected_refs])].copy()
        if a_df.empty:
            st.warning("Kh√¥ng c√≥ h√†nh ƒë·ªông ph√π h·ª£p v·ªõi b·ªô l·ªçc legal_reference hi·ªán t·∫°i.")
        else:
            if "action_type" in a_df.columns:
                act_count = a_df["action_type"].value_counts().reset_index()
                act_count.columns = ["Action_type","Count"]
                fig = px.pie(act_count, values="Count", names="Action_type", title="Ph√¢n lo·∫°i t√≠nh ch·∫•t bi·ªán ph√°p", hole=.35)
                fig.update_traces(textinfo="percent+label")
                st.plotly_chart(fig, use_container_width=True)
            st.markdown("---")
            cols = [c for c in ["legal_reference_filter","action_type","action_description","evidence_of_completion"] if c in a_df.columns]
            rename = {
                "legal_reference_filter":"Lu·∫≠t l·ªá (l·ªçc RAWx)",
                "action_type":"T√≠nh ch·∫•t bi·ªán ph√°p",
                "action_description":"N·ªôi dung c√¥ng vi·ªác ph·∫£i l√†m",
                "evidence_of_completion":"C√¥ng vi·ªác chi ti·∫øt / Minh ch·ª©ng"
            }
            st.dataframe(a_df[cols].rename(columns=rename), use_container_width=True, height=420)

st.caption("¬© KLTT Dashboard ‚Ä¢ Streamlit ‚Ä¢ Altair ‚Ä¢ Plotly")
