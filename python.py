# python.py
# Streamlit app: Dashboard tr·ª±c quan h√≥a K·∫øt lu·∫≠n Thanh tra (KLTT)
# Ch·∫°y: streamlit run python.py
# Y√™u c·∫ßu: pip install streamlit pandas altair openpyxl plotly

import io
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px

st.set_page_config(
    page_title="Dashboard K·∫øt lu·∫≠n Thanh tra (KLTT)",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==============================
# Helpers
# ==============================

@st.cache_data(show_spinner=False)
def load_excel(uploaded_file: io.BytesIO) -> dict:
    xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
    sheets = {s.lower().strip(): s for s in xls.sheet_names}
    out = {}
    for canon, real in sheets.items():
        df = pd.read_excel(xls, real)
        df.columns = [str(c).strip() for c in df.columns]
        out[canon] = df
    return out

def canonicalize_df(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()
    new_cols = {}
    existing_lower = {c.lower(): c for c in df.columns}
    for want, aliases in mapping.items():
        for alias in aliases:
            if alias.lower() in existing_lower:
                new_cols[existing_lower[alias.lower()]] = want
                break
    return df.rename(columns=new_cols)

def coalesce_series_with_raw(series: pd.Series, prefix="RAW"):
    s = series.copy()
    s = s.astype(str)
    null_mask = s.isna() | s.str.strip().eq("") | s.str.lower().eq("nan")
    if null_mask.any():
        raw_index = np.cumsum(null_mask).where(null_mask, 0)
        s.loc[null_mask] = [f"{prefix}{i}" for i in raw_index[null_mask].astype(int)]
    return s

def to_number(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int, float, np.number)): return float(x)
    try: return float(str(x).replace(",", "").replace(" ", ""))
    except:
        digits = "".join(ch for ch in str(x) if (ch.isdigit() or ch=='.' or ch=='-'))
        try: return float(digits)
        except: return np.nan

def safe_date(series: pd.Series):
    try: return pd.to_datetime(series, errors="coerce")
    except Exception: return pd.to_datetime(pd.Series([None]*len(series)), errors="coerce")

def format_vnd(n):
    if pd.isna(n): return "‚Äî"
    n = float(n)
    if abs(n) >= 1_000_000_000_000: return f"{n/1_000_000_000_000:.2f} ngh√¨n t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000_000:     return f"{n/1_000_000_000:.2f} t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000:         return f"{n/1_000_000:.2f} tri·ªáu ‚Ç´"
    return f"{n:,.0f} ‚Ç´"

# ==============================
# Theme + CSS
# ==============================

st.markdown("""
<style>
:root { --label-color: #1f6feb; }
[data-testid="stDataFrame"] td, [data-testid="stDataFrame"] th {
  white-space: pre-wrap !important;
  word-break: break-word !important;
}
.info-card { padding: 10px 12px; border: 1px solid #e8e8e8; border-radius: 10px; background: #fff; min-height: 72px; }
.info-card .label { font-size: 12px; color: var(--label-color); font-weight: 700; margin-bottom: 4px; }
.info-card .value { font-size: 15px; line-height: 1.4; white-space: pre-wrap; word-break: break-word; }
.doc-wrap { padding: 10px 14px; border: 1px solid #e6e6e6; border-radius: 12px; background: #fafcff; margin-bottom: 14px; }
.doc-title { font-weight: 700; font-size: 16px; margin-bottom: 8px; }
</style>
""", unsafe_allow_html=True)

def info_card(label, value):
    if value in [None, np.nan, "nan", "None"]:
        value = "‚Äî"
    st.markdown(
        f"""
        <div class="info-card">
          <div class="label"><b>{label}</b></div>
          <div class="value">{value}</div>
        </div>
        """, unsafe_allow_html=True
    )

# ==============================
# Column mappings
# ==============================

COL_MAP = {
    "documents": {
        "doc_id": ["Doc_id","doc_id","DocID","Maso"],
        "issue_date": ["Issue_date","Issues_date","issue_date"],
        "title": ["title","Title"],
        "issuing_authority": ["Issuing_authority","issuing_authority"],
        "inspected_entity_name": ["inspected_entity_name","Inspected_entity_name"],
        "sector": ["sector","Sector"],
        "period_start": ["period_start","Period_start"],
        "period_end": ["period_end","Period_end"],
        "signer_name": ["Signer_name","signer_name"],
        "signer_title": ["Signer_title","signer_title"],
    },
    "overalls": {
        "departments_at_hq_count": ["departments_at_hq_count"],
        "transaction_offices_count": ["transaction_offices_count"],
        "staff_total": ["staff_total"],
        "mobilized_capital_vnd": ["mobilized_capital_vnd"],
        "loans_outstanding_vnd": ["loans_outstanding_vnd"],
        "npl_total_vnd": ["npl_total_vnd"],
        "npl_ratio_percent": ["npl_ratio_percent"],
        "sample_total_files": ["sample_total_files"],
        "sample_outstanding_checked_vnd": ["sample_outstanding_checked_vnd"],

        # --- B·ªï sung theo y√™u c·∫ßu ---
        "npl_group3_vnd": ["npl_group3_vnd"],
        "npl_group4_vnd": ["npl_group4_vnd"],
        "npl_group5_vnd": ["npl_group5_vnd"],
        "structure_term_short_vnd": ["structure_term_short_vnd"],
        "structure_term_medium_long_vnd": ["structure_term_medium_long_vnd"],
        "structure_currency_vnd_vnd": ["structure_currency_vnd_vnd"],
        "structure_currency_fx_vnd": ["structure_currency_fx_vnd"],
        "structure_purpose_bds_flexible_vnd": ["structure_purpose_bds_flexible_vnd"],
        "strucuture_purpose_securities_vnd": ["strucuture_purpose_securities_vnd"],
        "structure_purpose_consumption_vnd": ["structure_purpose_consumption_vnd"],
        "structure_purpose_trade_vnd": ["structure_purpose_trade_vnd"],
        "structure_purpose_other_vnd": ["structure_purpose_other_vnd"],
        "strucuture_econ_state_vnd": ["strucuture_econ_state_vnd"],
        "strucuture_econ_nonstate_enterprises_vnd": ["strucuture_econ_nonstate_enterprises_vnd"],
        "strucuture_econ_individuals_households_vnd": ["strucuture_econ_individuals_households_vnd"]
    },
    "findings": {
        "category": ["category"],
        "sub_category": ["sub_category"],
        "description": ["description"],
        "legal_reference": ["legal_reference"],
        "quantified_amount": ["quantified_amount"],
        "impacted_accounts": ["impacted_accounts"],
        "root_cause": ["Root_cause","root_cause"],
        "recommendation": ["recommendation"],
    },
    "actions": {
        "action_type": ["action_type"],
        "legal_reference": ["legal_reference"],
        "action_description": ["action_description"],
        "evidence_of_completion": ["evidence_of_completion"],
    }
}

# ==============================
# Sidebar (Upload + Filters)
# ==============================

with st.sidebar:
    st.header("üì§ T·∫£i d·ªØ li·ªáu")
    uploaded = st.file_uploader("Excel (.xlsx): documents, overalls, findings, (actions tu·ª≥ ch·ªçn)", type=["xlsx"])
    st.caption("T√™n sheet & c·ªôt kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng.")

st.title("üõ°Ô∏è Dashboard B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra")

if not uploaded:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

data = load_excel(uploaded)

def get_df(sheet_key):
    raw = data.get(sheet_key)
    mapping = COL_MAP.get(sheet_key, {})
    if raw is None: return pd.DataFrame()
    return canonicalize_df(raw.copy(), mapping)

df_docs = get_df("documents")
df_over = get_df("overalls")
df_find = get_df("findings")
df_act  = get_df("actions")

if df_docs.empty or df_over.empty or df_find.empty:
    st.error("Thi·∫øu m·ªôt trong c√°c sheet b·∫Øt bu·ªôc: documents, overalls, findings.")
    st.stop()

# Dates
for c in ["issue_date","period_start","period_end"]:
    if c in df_docs.columns:
        df_docs[c] = safe_date(df_docs[c])

# Numeric
for c in COL_MAP["overalls"].keys():
    if c in df_over.columns: df_over[c] = df_over[c].apply(to_number)
for c in ["quantified_amount","impacted_accounts"]:
    if c in df_find.columns: df_find[c] = df_find[c].apply(to_number)

# RAW handling
df_find["legal_reference_filter"] = coalesce_series_with_raw(df_find["legal_reference"], prefix="RAW")
df_find["legal_reference_chart"] = df_find["legal_reference_filter"].apply(lambda x: "RAW" if str(x).startswith("RAW") else x)

# Sidebar filter (findings only)
st.sidebar.header("üîé L·ªçc Findings")
all_refs = sorted(df_find["legal_reference_filter"].astype(str).unique().tolist())
selected_refs = st.sidebar.multiselect("Ch·ªçn Legal_reference", options=all_refs, default=all_refs)
f_df = df_find[df_find["legal_reference_filter"].astype(str).isin([str(x) for x in selected_refs])].copy()

st.sidebar.markdown("---")
st.sidebar.metric("üí∏ T·ªïng ti·ªÅn ·∫£nh h∆∞·ªüng (l·ªçc)", format_vnd(f_df["quantified_amount"].sum()))
st.sidebar.metric("üë• T·ªïng h·ªì s∆° ·∫£nh h∆∞·ªüng (l·ªçc)", f"{int(f_df['impacted_accounts'].sum()) if 'impacted_accounts' in f_df.columns and pd.notna(f_df['impacted_accounts'].sum()) else '‚Äî'}")

# ==============================
# Tabs
# ==============================

tab_docs, tab_over, tab_find, tab_act = st.tabs(["üìù Documents","üìä Overalls","üö® Findings","‚úÖ Actions"])

# ---- Documents ----
with tab_docs:
    st.header("B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra (Metadata)")
    st.markdown("---")
    for _, row in df_docs.iterrows():
        st.markdown(f"### üìù {row.get('doc_id','‚Äî')}")
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            info_card("ƒê∆°n v·ªã ph√°t h√†nh", row.get("issuing_authority"))
        with c2:
            info_card("Ng√†y ph√°t h√†nh", row.get("issue_date"))
        with c3:
            info_card("Ng∆∞·ªùi k√Ω", row.get("signer_name"))
        with c4:
            info_card("Ch·ª©c v·ª•", row.get("signer_title"))

# ---- Overalls ----
with tab_over:
    st.header("Th√¥ng Tin T·ªïng Quan")
    st.markdown("---")
    over_row = df_over.iloc[-1] if len(df_over) else pd.Series({})

    k1,k2,k3,k4,k5 = st.columns(5)
    with k1:
        st.metric("T·ªïng nh√¢n s·ª±", f"{int(over_row.get('staff_total', np.nan)) if pd.notna(over_row.get('staff_total', np.nan)) else '‚Äî'}")
        st.metric("M·∫´u ki·ªÉm tra", f"{int(over_row.get('sample_total_files', np.nan)) if pd.notna(over_row.get('sample_total_files', np.nan)) else '‚Äî'}")
    with k2:
        st.metric("Ph√≤ng nghi·ªáp v·ª•", f"{int(over_row.get('departments_at_hq_count', np.nan)) if pd.notna(over_row.get('departments_at_hq_count', np.nan)) else '‚Äî'}")
        st.metric("Ph√≤ng giao d·ªãch", f"{int(over_row.get('transaction_offices_count', np.nan)) if pd.notna(over_row.get('transaction_offices_count', np.nan)) else '‚Äî'}")
    with k3:
        st.metric("Ngu·ªìn v·ªën", format_vnd(over_row.get("mobilized_capital_vnd", np.nan)))
    with k4:
        st.metric("D∆∞ n·ª£", format_vnd(over_row.get("loans_outstanding_vnd", np.nan)))
    with k5:
        st.metric("N·ª£ x·∫•u", format_vnd(over_row.get("npl_total_vnd", np.nan)))
        st.metric("T·ª∑ l·ªá NPL/D∆∞ n·ª£", f"{over_row.get('npl_ratio_percent', np.nan):.2f}%" if pd.notna(over_row.get('npl_ratio_percent', np.nan)) else "‚Äî")

    st.markdown("### üìå N·ª£ x·∫•u theo nh√≥m (n·∫øu c√≥)")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("N·ª£ x·∫•u nh√≥m 3", format_vnd(over_row.get("npl_group3_vnd", np.nan)))
    with c2:
        st.metric("N·ª£ x·∫•u nh√≥m 4", format_vnd(over_row.get("npl_group4_vnd", np.nan)))
    with c3:
        st.metric("N·ª£ x·∫•u nh√≥m 5", format_vnd(over_row.get("npl_group5_vnd", np.nan)))

    st.markdown("### üß≠ C∆° c·∫•u theo k·ª≥ h·∫°n")
    t1, t2 = st.columns(2)
    with t1:
        st.metric("D∆∞ n·ª£ ng·∫Øn h·∫°n", format_vnd(over_row.get("structure_term_short_vnd", np.nan)))
    with t2:
        st.metric("D∆∞ n·ª£ trung & d√†i h·∫°n", format_vnd(over_row.get("structure_term_medium_long_vnd", np.nan)))

    st.markdown("### üí± C∆° c·∫•u theo ti·ªÅn t·ªá")
    cur1, cur2 = st.columns(2)
    with cur1:
        st.metric("D∆∞ n·ª£ b·∫±ng VND", format_vnd(over_row.get("structure_currency_vnd_vnd", np.nan)))
    with cur2:
        st.metric("D∆∞ n·ª£ quy ƒë·ªïi ngo·∫°i t·ªá", format_vnd(over_row.get("structure_currency_fx_vnd", np.nan)))

    st.markdown("### üéØ C∆° c·∫•u theo m·ª•c ƒë√≠ch vay")
    g1, g2, g3 = st.columns(3)
    with g1:
        st.metric("BƒêS / linh ho·∫°t", format_vnd(over_row.get("structure_purpose_bds_flexible_vnd", np.nan)))
        st.metric("Ch·ª©ng kho√°n", format_vnd(over_row.get("strucuture_purpose_securities_vnd", np.nan)))
    with g2:
        st.metric("Ti√™u d√πng", format_vnd(over_row.get("structure_purpose_consumption_vnd", np.nan)))
        st.metric("Th∆∞∆°ng m·∫°i", format_vnd(over_row.get("structure_purpose_trade_vnd", np.nan)))
    with g3:
        st.metric("M·ª•c ƒë√≠ch kh√°c", format_vnd(over_row.get("structure_purpose_other_vnd", np.nan)))

    st.markdown("### üß© C∆° c·∫•u theo th√†nh ph·∫ßn kinh t·∫ø")
    e1, e2, e3 = st.columns(3)
    with e1:
        st.metric("DN Nh√† n∆∞·ªõc", format_vnd(over_row.get("strucuture_econ_state_vnd", np.nan)))
    with e2:
        st.metric("DN ngo√†i QD", format_vnd(over_row.get("strucuture_econ_nonstate_enterprises_vnd", np.nan)))
    with e3:
        st.metric("C√° nh√¢n/H·ªô gia ƒë√¨nh", format_vnd(over_row.get("strucuture_econ_individuals_households_vnd", np.nan)))

st.caption("¬© KLTT Dashboard ‚Ä¢ Streamlit ‚Ä¢ Altair ‚Ä¢ Plotly")
