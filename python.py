import io
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="Dashboard K·∫øt lu·∫≠n Thanh tra (KLTT)",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -----------------------------
# 1. HELPERS & UTILITIES
# -----------------------------

@st.cache_data(show_spinner=False)
def load_excel(uploaded_file: io.BytesIO) -> dict:
    """ƒê·ªçc t·∫•t c·∫£ c√°c sheet t·ª´ file Excel v√† chu·∫©n h√≥a t√™n c·ªôt."""
    xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
    # T√™n sheet chu·∫©n h√≥a (lowercase, strip)
    sheets = {s.lower().strip(): s for s in xls.sheet_names}
    dfs = {}
    
    with st.spinner("ƒêang t·∫£i v√† chu·∫©n h√≥a d·ªØ li·ªáu..."):
        for canon, real in sheets.items():
            df = pd.read_excel(xls, real)
            # Chu·∫©n h√≥a t√™n c·ªôt: strip
            df.columns = [str(c).strip() for c in df.columns]
            dfs[canon] = df
    return dfs

def canonicalize_df(df, mapping):
    """√Ånh x·∫° t√™n c·ªôt (k·ªÉ c·∫£ ch·ªØ hoa/th∆∞·ªùng) sang t√™n chu·∫©n."""
    new_cols = {}
    # L·∫•y mapping t·ª´ t√™n c·ªôt hi·ªán t·∫°i (lowercase) sang t√™n c·ªôt g·ªëc
    existing_lower = {c.lower(): c for c in df.columns}
    
    for want_lower, aliases in mapping.items():
        # T√¨m c·ªôt kh·ªõp v·ªõi b·∫•t k·ª≥ alias n√†o
        found_col = None
        for alias in aliases:
            if alias.lower() in existing_lower:
                found_col = existing_lower[alias.lower()]
                break
        
        if found_col:
            # G√°n l·∫°i t√™n c·ªôt chu·∫©n (v√≠ d·ª•: 'legal_reference')
            new_cols[found_col] = want_lower
    
    return df.rename(columns=new_cols)

def coalesce_series_with_raw(series: pd.Series, prefix="RAW"):
    """Thay th·∫ø c√°c gi√° tr·ªã r·ªóng/NaN b·∫±ng RAW1, RAW2..."""
    s = series.copy().astype(str).str.strip()
    # Mask cho c√°c gi√° tr·ªã r·ªóng, NaN ho·∫∑c ch·ªâ kho·∫£ng tr·∫Øng
    null_mask = s.isna() | s.eq("") | s.str.lower().eq("nan")
    
    if null_mask.any():
        # G√°n nh√£n RAW duy nh·∫•t cho m·ªói √¥ tr·ªëng
        raw_index = np.cumsum(null_mask).where(null_mask, 0)
        s.loc[null_mask] = [f"{prefix}-{i:02d}" for i in raw_index[null_mask].astype(int)]
    
    return s.replace({f"{prefix}-00": np.nan}) # Lo·∫°i b·ªè index 0 n·∫øu c√≥

def to_number(x):
    """Chuy·ªÉn ƒë·ªïi gi√° tr·ªã sang s·ªë, x·ª≠ l√Ω c√°c ƒë·ªãnh d·∫°ng ti·ªÅn t·ªá c∆° b·∫£n."""
    if pd.isna(x):
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    try:
        # X√≥a d·∫•u ph·∫©y, kho·∫£ng tr·∫Øng ƒë·ªÉ chuy·ªÉn ƒë·ªïi
        return float(str(x).replace(",", "").replace(" ", ""))
    except:
        return np.nan

def format_vnd(amount):
    """ƒê·ªãnh d·∫°ng ti·ªÅn t·ªá sang T·ª∑/Tri·ªáu VND"""
    if pd.isna(amount):
        return "‚Äî"
    if abs(amount) >= 1_000_000_000_000:
        return f"{amount / 1_000_000_000_000:.2f} ngh√¨n t·ª∑ ‚Ç´"
    elif abs(amount) >= 1_000_000_000:
        return f"{amount / 1_000_000_000:.2f} t·ª∑ ‚Ç´"
    elif abs(amount) >= 1_000_000:
        return f"{amount / 1_000_000:.2f} tri·ªáu ‚Ç´"
    else:
        return f"{amount:,.0f} ‚Ç´"

def format_metric(value, unit=""):
    """ƒê·ªãnh d·∫°ng s·ªë l·ªõn"""
    if pd.isna(value):
        return "‚Äî"
    if abs(value) >= 1_000_000_000_000:
        return f"{value / 1e12:.2f} T"
    elif abs(value) >= 1_000_000_000:
        return f"{value / 1e9:.2f} T·ª∑"
    elif abs(value) >= 1_000_000:
        return f"{value / 1e6:.2f} Tr"
    return f"{value:,.0f} {unit}"

# -----------------------------
# 2. DATA MAPPING & LOAD
# -----------------------------

# T√™n c·ªôt chu·∫©n h√≥a v√† c√°c t√™n thay th·∫ø (alias) c√≥ th·ªÉ ch·∫•p nh·∫≠n
COL_MAPPING = {
    "documents": {
        "doc_id": ["doc_id", "Doc_code", "Maso", "MaKLTT"],
        "issue_date": ["issue_date", "Issues_date", "NgayPH"],
        "title": ["title", "Tieude"],
        "issuing_authority": ["issuing_authority", "DVphanh", "CquanPH"],
        "inspected_entity_name": ["inspected_entity_name", "DVkiemtra", "DonviKT"],
        "sector": ["sector", "Linhvuc"],
        "period_start": ["period_start", "Batdau"],
        "period_end": ["period_end", "Ketthuc"],
        "signer_name": ["signer_name", "Nguoiky", "Signer_name"],
        "signer_title": ["signer_title", "Chucvu", "Signer_title"],
    },
    "overalls": {
        "departments_at_hq_count": ["departments_at_hq_count", "PhongKD", "SoPhong"],
        "transaction_offices_count": ["transaction_offices_count", "PhongGD", "SoGD"],
        "staff_total": ["staff_total", "TongNV", "NV"],
        "mobilized_capital_vnd": ["mobilized_capital_vnd", "Nguonvon", "Vondong"],
        "loans_outstanding_vnd": ["loans_outstanding_vnd", "Soduno", "Duno"],
        "npl_total_vnd": ["npl_total_vnd", "Noxau", "TongNPL"],
        "npl_ratio_percent": ["npl_ratio_percent", "Ty le NPL", "NPLrate"],
        "sample_total_files": ["sample_total_files", "Somau", "MauKT"],
        "sample_outstanding_checked_vnd": ["sample_outstanding_checked_vnd", "DunoKT", "TienmauKT"],
    },
    "findings": {
        "category": ["category", "MucLoi", "PhanLoai"],
        "sub_category": ["sub_category", "LoiCT", "TieuPhanLoai"],
        "description": ["description", "Mota", "Noidung"],
        # C·ªôt legal_reference b·∫Øt bu·ªôc ƒë·ªÉ li√™n k·∫øt v·ªõi Actions
        "legal_reference": ["legal_reference", "Dieuluat", "Quy dinh", "Thamchieu"], 
        "quantified_amount": ["quantified_amount", "Sotien", "TienAnhhuong"],
        "impacted_accounts": ["impacted_accounts", "SoHoSo", "SoKH"],
        "root_cause": ["root_cause", "Nguyengoc", "LyDo"],
        "recommendation": ["recommendation", "Kiennghi", "DeXuat"],
        # C√ÅC C·ªòT ACTION ƒê√É ƒê∆Ø·ª¢C CHUY·ªÇN SANG MAPPING "actions" RI√äNG BI·ªÜT
    },
    "actions": { # MAPPING M·ªöI CHO SHEET ACTIONS
        "legal_reference": ["legal_reference", "Dieuluat", "Quy dinh", "Thamchieu"], # D√πng ƒë·ªÉ l·ªçc v√† li√™n k·∫øt
        "action_type": ["action_type", "LoaiAction", "Tinhchat"],
        "action_description": ["action_description", "MotaAction", "NoidungXP"],
        "evidence_of_completion": ["evidence_of_completion", "Minhchung", "Hoanthanh"],
    }
}

# --- Giao di·ªán ·ª®ng d·ª•ng ---

st.title("üõ°Ô∏è Dashboard B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra")

# T·∫£i file Excel
uploaded_file = st.file_uploader(
    # C·∫≠p nh·∫≠t m√¥ t·∫£ ƒë·ªÉ bao g·ªìm sheet actions
    "T·∫£i l√™n file Excel (.xlsx) ch·ª©a c√°c sheet: **documents, overalls, findings, actions**", 
    type=["xlsx"]
)

if not uploaded_file:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu. ·ª®ng d·ª•ng s·∫Ω t·ª± ƒë·ªông c·ªë g·∫Øng nh·∫≠n di·ªán t√™n c√°c c·ªôt.")
    st.stop()

# Load data from Excel
data = load_excel(uploaded_file)

# L·∫•y d·ªØ li·ªáu t·ª´ c√°c sheet v√† chu·∫©n h√≥a t√™n c·ªôt
def get_processed_df(sheet_name):
    df_raw = data.get(sheet_name)
    # T√™n sheet chu·∫©n h√≥a (v√≠ d·ª•: 'actions') s·∫Ω ƒë∆∞·ª£c d√πng ƒë·ªÉ ki·ªÉm tra COL_MAPPING
    mapping = COL_MAPPING.get(sheet_name)
    
    if df_raw is None or mapping is None:
        # N·∫øu kh√¥ng c√≥ sheet ho·∫∑c mapping, tr·∫£ v·ªÅ DF r·ªóng nh∆∞ng kh√¥ng b√°o l·ªói n·∫øu sheet kh√¥ng b·∫Øt bu·ªôc
        return pd.DataFrame() 
    
    # Chu·∫©n h√≥a t√™n c·ªôt b·∫±ng mapping ƒë√£ ƒë·ªãnh nghƒ©a
    df_canonical = canonicalize_df(df_raw.copy(), mapping)
    
    # Ki·ªÉm tra c·ªôt b·∫Øt bu·ªôc
    required_cols = list(mapping.keys())
    missing_cols = [col for col in required_cols if col not in df_canonical.columns]
    
    # Ch·ªâ check nghi√™m ng·∫∑t c√°c sheet 'documents', 'findings', 'actions'
    if missing_cols and sheet_name in ["documents", "findings", "actions"]:
        st.error(f"Sheet **'{sheet_name}'** thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a: **{', '.join(missing_cols)}**. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n c·ªôt trong file Excel.")
        st.stop()
        
    return df_canonical

# T·∫£i 4 sheet ch√≠nh
df_docs = get_processed_df("documents")
df_over = get_processed_df("overalls")
df_findings = get_processed_df("findings")
df_actions = get_processed_df("actions") # T·∫£i sheet Actions ri√™ng bi·ªát

# --- X·ª¨ L√ù D·ªÆ LI·ªÜU CHUNG ---

# X·ª≠ l√Ω c√°c c·ªôt ng√†y th√°ng
date_cols = ["issue_date", "period_start", "period_end"]
for col in date_cols:
    if col in df_docs.columns:
        df_docs[col] = pd.to_datetime(df_docs[col], errors='coerce')
        
# X·ª≠ l√Ω c·ªôt s·ªë trong Overalls
num_over_cols = [c for c in COL_MAPPING['overalls'] if c in df_over.columns]
for col in num_over_cols:
    df_over[col] = df_over[col].apply(to_number)
    
# X·ª≠ l√Ω c·ªôt s·ªë trong Findings
num_find_cols = ["quantified_amount", "impacted_accounts"]
for col in num_find_cols:
    if col in df_findings.columns:
        df_findings[col] = df_findings[col].apply(to_number)

# X·ª¨ L√ù L·ªñI 'legal_reference' (RAW) cho df_findings
if "legal_reference" in df_findings.columns:
    df_findings["legal_reference_filter"] = coalesce_series_with_raw(df_findings["legal_reference"], prefix="RAW")
    
    # T·∫°o c·ªôt cho m·ª•c ƒë√≠ch bi·ªÉu ƒë·ªì (gom t·∫•t c·∫£ RAW l·∫°i th√†nh 1 nh√≥m)
    df_findings['legal_reference_chart'] = df_findings['legal_reference_filter'].apply(
        lambda x: 'RAW (Ch∆∞a x√°c ƒë·ªãnh)' if 'RAW' in str(x) and str(x) != x else x
    )
else:
    # N·∫øu c·ªôt legal_reference ho√†n to√†n kh√¥ng t·ªìn t·∫°i
    st.error("Sheet 'findings' kh√¥ng c√≥ c·ªôt 'legal_reference' (ho·∫∑c t√™n thay th·∫ø t∆∞∆°ng ƒë∆∞∆°ng) ƒë·ªÉ li√™n k·∫øt. Vui l√≤ng ki·ªÉm tra l·∫°i.")
    st.stop()


# L·∫•y d·ªØ li·ªáu Documents v√† Overalls (Ch·ªâ l·∫•y h√†ng ƒë·∫ßu ti√™n)
if not df_docs.empty:
    doc_data = df_docs.iloc[0].to_dict()
else:
    doc_data = {c: "Kh√¥ng c√≥ d·ªØ li·ªáu" for c in COL_MAPPING["documents"]}
    
if not df_over.empty:
    # L·∫•y h√†ng cu·ªëi c√πng ho·∫∑c t·ªïng h·ª£p n·∫øu c√≥ nhi·ªÅu h√†ng
    over_data = df_over.iloc[-1].to_dict()
else:
    over_data = {c: np.nan for c in COL_MAPPING["overalls"]}


# --- SIDEBAR: FILTER ---
st.sidebar.header("üîç B·ªô L·ªçc Ph√°t Hi·ªán (Findings Filter)")

unique_legal_refs = sorted(df_findings['legal_reference_filter'].astype(str).unique())
selected_refs = st.sidebar.multiselect(
    "Ch·ªçn (c√°c) ƒêi·ªÅu lu·∫≠t/Quy ƒë·ªãnh Vi ph·∫°m:",
    options=unique_legal_refs,
    default=unique_legal_refs # M·∫∑c ƒë·ªãnh ch·ªçn t·∫•t c·∫£
)

# L·ªçc DataFrame Findings
df_filtered = df_findings[df_findings['legal_reference_filter'].astype(str).isin([str(x) for x in selected_refs])]

# L·ªçc DataFrame Actions (D√πng chung b·ªô l·ªçc legal_reference)
df_actions_filtered = pd.DataFrame()
if not df_actions.empty and "legal_reference" in df_actions.columns:
    df_actions["legal_reference_filter"] = coalesce_series_with_raw(df_actions["legal_reference"], prefix="RAW")
    df_actions_filtered = df_actions[df_actions['legal_reference_filter'].astype(str).isin([str(x) for x in selected_refs])]

# Hi·ªÉn th·ªã s·ªë li·ªáu t·ªïng h·ª£p trong sidebar
st.sidebar.markdown("---")
total_quantified = df_filtered['quantified_amount'].sum() if 'quantified_amount' in df_filtered.columns else 0
total_impacted = df_filtered['impacted_accounts'].sum() if 'impacted_accounts' in df_filtered.columns else 0

st.sidebar.metric(
    label="üí∏ T·ªïng Ti·ªÅn B·ªã ·∫¢nh H∆∞·ªüng (L·ªçc)",
    value=format_vnd(total_quantified)
)
st.sidebar.metric(
    label="üë§ T·ªïng H·ªì S∆° B·ªã ·∫¢nh H∆∞·ªüng (L·ªçc)",
    value=f"{total_impacted:,.0f}"
)


# --- B·ªê C·ª§C CH√çNH (TABS) ---
tab1, tab2, tab3, tab4 = st.tabs(["üìù Documents", "üìä Overalls", "üö® Findings", "‚úÖ Actions"])

# ====================================
# TAB 1: DOCUMENTS (Metadata)
# ====================================
with tab1:
    st.header("B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra (Metadata)")
    st.markdown("---")
    
    col1, col2 = st.columns([1, 2])
    
    # ƒê·ªãnh d·∫°ng l·∫°i ng√†y th√°ng
    def safe_date_format(date_obj):
        return date_obj.strftime('%d/%m/%Y') if pd.notna(date_obj) else "‚Äî"

    with col1:
        st.markdown(f"**M√£ s·ªë k·∫øt lu·∫≠n thanh tra:** `{doc_data.get('doc_id', '‚Äî')}`")
        st.markdown(f"**Ng√†y ph√°t h√†nh:** `{safe_date_format(doc_data.get('issue_date'))}`")
        st.markdown(f"**Lƒ©nh v·ª±c:** `{doc_data.get('sector', '‚Äî')}`")
        st.markdown(f"**Ng∆∞·ªùi ki·ªÉm so√°t:** `{doc_data.get('signer_name', '‚Äî')}`")
        st.markdown(f"**Ch·ª©c v·ª•:** `{doc_data.get('signer_title', '‚Äî')}`")
        st.markdown(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** `{safe_date_format(doc_data.get('period_start'))}`")
        st.markdown(f"**Th·ªùi gian k·∫øt th√∫c:** `{safe_date_format(doc_data.get('period_end'))}`")

    with col2:
        st.markdown("**Title c·ªßa k·∫øt lu·∫≠n thanh tra:**")
        st.info(doc_data.get('title', '‚Äî'))
        
        st.markdown("**ƒê∆°n v·ªã ph√°t h√†nh:**")
        st.info(doc_data.get('issuing_authority', '‚Äî'))
        
        st.markdown("**ƒê∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm tra:**")
        st.info(doc_data.get('inspected_entity_name', '‚Äî'))

# ====================================
# TAB 2: OVERALLS (Metrics)
# ====================================
with tab2:
    st.header("Th√¥ng Tin T·ªïng Quan V·ªÅ ƒê∆°n V·ªã ƒê∆∞·ª£c Ki·ªÉm Tra")
    st.markdown("---")

    col_staff, col_offices, col_capital, col_loan, col_npl = st.columns(5)

    with col_staff:
        st.metric("T·ªïng s·ªë l∆∞·ª£ng nh√¢n vi√™n", f"{over_data.get('staff_total', np.nan):,.0f}" if pd.notna(over_data.get('staff_total')) else "‚Äî")
        st.metric("S·ªë l∆∞·ª£ng m·∫´u ki·ªÉm tra", f"{over_data.get('sample_total_files', np.nan):,.0f}" if pd.notna(over_data.get('sample_total_files')) else "‚Äî")
    
    with col_offices:
        st.metric("Ph√≤ng nghi·ªáp v·ª• (HQ_count)", f"{over_data.get('departments_at_hq_count', np.nan):,.0f}" if pd.notna(over_data.get('departments_at_hq_count')) else "‚Äî")
        st.metric("Ph√≤ng giao d·ªãch (Transaction_offices_count)", f"{over_data.get('transaction_offices_count', np.nan):,.0f}" if pd.notna(over_data.get('transaction_offices_count')) else "‚Äî")

    with col_capital:
        st.metric("T·ªïng s·ªë ngu·ªìn v·ªën", format_metric(over_data.get('mobilized_capital_vnd')))

    with col_loan:
        st.metric("T·ªïng s·ªë d∆∞ n·ª£", format_metric(over_data.get('loans_outstanding_vnd')))

    with col_npl:
        st.metric("T·ªïng s·ªë n·ª£ x·∫•u", format_metric(over_data.get('npl_total_vnd')))
        st.metric("T·ª∑ l·ªá NPL (%)", f"{over_data.get('npl_ratio_percent', np.nan):.2f}%" if pd.notna(over_data.get('npl_ratio_percent')) else "‚Äî")
        st.metric("T·ªïng ti·ªÅn ki·ªÉm tra", format_metric(over_data.get('sample_outstanding_checked_vnd')))


# ====================================
# TAB 3: FINDINGS (Ph√°t hi·ªán & Nguy√™n nh√¢n)
# ====================================
with tab3:
    st.header("Ph√¢n T√≠ch Chi Ti·∫øt Ph√°t Hi·ªán (Findings)")
    st.subheader(f"D·ªØ li·ªáu ƒëang ƒë∆∞·ª£c l·ªçc theo: **{len(selected_refs)}/{len(unique_legal_refs)} ƒëi·ªÅu lu·∫≠t**")
    st.markdown("---")
    
    if df_filtered.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ph√°t hi·ªán n√†o kh·ªõp v·ªõi b·ªô l·ªçc hi·ªán t·∫°i.")
    else:
        # ------------------
        # 3.1. Bi·ªÉu ƒë·ªì Ph√¢n lo·∫°i
        # ------------------
        col_cat, col_sub_cat = st.columns(2)
        
        # Chart 1: Bi·ªÉu ƒë·ªì Bar cho Category
        with col_cat:
            st.subheader("1. S·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa c√°c M·ª•c L·ªói (Category)")
            df_category_count = df_filtered['category'].value_counts().reset_index()
            df_category_count.columns = ['Category', 'Count']
            
            fig_cat = px.bar(
                df_category_count, 
                x='Category', 
                y='Count', 
                text='Count',
                title='Th·ªëng k√™ l·ªói theo Category',
                color='Category'
            )
            fig_cat.update_traces(textposition='outside')
            fig_cat.update_layout(height=400, xaxis_title="", yaxis_title="S·ªë l·∫ßn xu·∫•t hi·ªán")
            st.plotly_chart(fig_cat, use_container_width=True)

        # Chart 2: Bi·ªÉu ƒë·ªì C·ªôt (Grouped Bar) cho Sub-category ph√¢n theo Category
        with col_sub_cat:
            st.subheader("2. Ph√¢n lo·∫°i L·ªói Chi ti·∫øt (Sub-category theo Category)")
            df_grouped = df_filtered.groupby(['category', 'sub_category']).size().reset_index(name='Count')
            
            fig_sub_cat = px.bar(
                df_grouped, 
                x='category', 
                y='Count', 
                color='sub_category',
                title='Sub-category Count trong t·ª´ng Category',
                labels={'category': 'M·ª•c L·ªói (Category)', 'Count': 'S·ªë l·∫ßn xu·∫•t hi·ªán', 'sub_category': 'L·ªói Chi ti·∫øt'}
            )
            fig_sub_cat.update_layout(barmode='group', height=400, xaxis_title="M·ª•c L·ªói")
            st.plotly_chart(fig_sub_cat, use_container_width=True)
            
        st.markdown("---")
        
        # ------------------
        # 3.2. Bi·ªÉu ƒë·ªì Line Chart cho Legal Reference
        # ------------------
        st.subheader("3. Xu h∆∞·ªõng L·ªói theo ƒêi·ªÅu Lu·∫≠t/Quy ƒë·ªãnh (Legal Reference)")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho Line Chart: S·ª≠ d·ª•ng c·ªôt legal_reference_chart ƒë√£ gom 'RAW'
        df_legal_count = df_filtered['legal_reference_chart'].value_counts().reset_index()
        df_legal_count.columns = ['Legal_Reference', 'Count']

        fig_line = px.line(
            df_legal_count,
            x='Legal_Reference',
            y='Count',
            markers=True,
            title="S·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa t·ª´ng ƒëi·ªÅu lu·∫≠t (Gom nh√≥m RAW)",
            labels={'Legal_Reference': 'ƒêi·ªÅu Lu·∫≠t/Quy ƒë·ªãnh', 'Count': 'S·ªë l·∫ßn xu·∫•t hi·ªán'}
        )
        
        st.plotly_chart(fig_line, use_container_width=True)
        st.markdown("""
            <div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
                **Ch√∫ th√≠ch:** *RAW (Ch∆∞a x√°c ƒë·ªãnh)* l√† nh√≥m t·ªïng h·ª£p c√°c sai ph·∫°m m√† ƒëi·ªÅu lu·∫≠t/quy ƒë·ªãnh kh√¥ng ƒë∆∞·ª£c nh·∫Øc t·ªõi r√µ r√†ng trong file g·ªëc (ƒë√£ ƒë∆∞·ª£c ƒë√°nh s·ªë t·ª´ RAW-01, RAW-02...).
            </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")

        # ------------------
        # 3.3. B·∫£ng Chi ti·∫øt v√† Ph√¢n t√≠ch Nguy√™n nh√¢n
        # ------------------
        st.subheader("4. Chi ti·∫øt Sai ph·∫°m, Nguy√™n nh√¢n v√† Ki·∫øn ngh·ªã")
        
        # Nh√≥m d·ªØ li·ªáu theo sub_category ƒë·ªÉ hi·ªÉn th·ªã b·∫£ng chi ti·∫øt
        sub_categories = df_filtered['sub_category'].unique()

        for sub_cat in sub_categories:
            st.markdown(f"#### üîé L·ªói Chi ti·∫øt: **{sub_cat}** (S·ªë l·∫ßn xu·∫•t hi·ªán: {len(df_filtered[df_filtered['sub_category'] == sub_cat]):,})")
            
            # L·ª±a ch·ªçn c√°c c·ªôt c·∫ßn hi·ªÉn th·ªã (Kh√¥ng c√≤n c·ªôt action_type, action_description, evidence_of_completion)
            display_cols = ['legal_reference_filter', 'description', 'quantified_amount', 'impacted_accounts']
            if 'root_cause' in df_filtered.columns:
                display_cols.append('root_cause')
            if 'recommendation' in df_filtered.columns:
                display_cols.append('recommendation')
                
            df_sub_cat = df_filtered[df_filtered['sub_category'] == sub_cat].reset_index(drop=True)[display_cols]
            
            # ƒê·ªïi t√™n c·ªôt hi·ªÉn th·ªã
            rename_map = {
                'legal_reference_filter': 'Lu·∫≠t L·ªá (RAW-XX)',
                'description': 'M√¥ t·∫£ Sai ph·∫°m',
                'quantified_amount': 'S·ªë ti·ªÅn ·∫¢nh h∆∞·ªüng (VND)',
                'impacted_accounts': 'S·ªë KH/H·ªì s∆° ·∫¢nh h∆∞·ªüng',
                'root_cause': 'Nguy√™n nh√¢n G·ªëc',
                'recommendation': 'Ki·∫øn ngh·ªã Thay ƒë·ªïi'
            }
            
            # B·∫£ng hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß
            st.dataframe(
                df_sub_cat.rename(columns=rename_map).style.format({
                    'S·ªë ti·ªÅn ·∫¢nh h∆∞·ªüng (VND)': lambda x: format_vnd(x),
                    'S·ªë KH/H·ªì s∆° ·∫¢nh h∆∞·ªüng': lambda x: f"{x:,.0f}" if pd.notna(x) else "‚Äî"
                }),
                use_container_width=True,
                height=300
            )
            st.markdown("---")

# ====================================
# TAB 4: ACTIONS (Bi·ªán ph√°p Kh·∫Øc ph·ª•c)
# ====================================
with tab4:
    st.header("Ph√¢n T√≠ch Bi·ªán Ph√°p Kh·∫Øc Ph·ª•c (Actions)")
    st.subheader(f"D·ªØ li·ªáu H√†nh ƒë·ªông ƒëang ƒë∆∞·ª£c l·ªçc theo: **{len(selected_refs)}/{len(unique_legal_refs)} ƒëi·ªÅu lu·∫≠t**")
    st.markdown("---")
    
    # S·ª¨ D·ª§NG DATAFRAME ƒê√É L·ªåC RI√äNG CHO ACTIONS
    if df_actions_filtered.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu h√†nh ƒë·ªông n√†o kh·ªõp v·ªõi b·ªô l·ªçc hi·ªán t·∫°i ho·∫∑c sheet 'actions' kh√¥ng t·ªìn t·∫°i/b·ªã thi·∫øu c·ªôt.")
    else:
        # ------------------
        # 4.1. Bi·ªÉu ƒë·ªì Ph√¢n lo·∫°i H√†nh ƒë·ªông
        # ------------------
        if 'action_type' in df_actions_filtered.columns:
            st.subheader("1. Ph√¢n lo·∫°i T√≠nh ch·∫•t c·ªßa Bi·ªán ph√°p C·∫£i t·∫°o (Action Type)")
            df_action_count = df_actions_filtered['action_type'].value_counts().reset_index()
            df_action_count.columns = ['Action_Type', 'Count']
            
            fig_action = px.pie(
                df_action_count, 
                values='Count', 
                names='Action_Type', 
                title='Ph√¢n lo·∫°i Bi·ªán ph√°p C·∫£i t·∫°o',
                hole=.3
            )
            fig_action.update_traces(textinfo='percent+label', marker=dict(line=dict(color='#000000', width=1)))
            st.plotly_chart(fig_action, use_container_width=True)
            st.markdown("---")
        
        # ------------------
        # 4.2. B·∫£ng Chi ti·∫øt H√†nh ƒë·ªông
        # ------------------
        st.subheader("2. B·∫£ng Chi ti·∫øt K·∫ø ho·∫°ch H√†nh ƒë·ªông (Action Plan)")
        
        # L·ª±a ch·ªçn c√°c c·ªôt h√†nh ƒë·ªông c·∫ßn hi·ªÉn th·ªã
        action_cols = ['legal_reference_filter', 'action_type', 'action_description', 'evidence_of_completion']
        action_cols = [c for c in action_cols if c in df_actions_filtered.columns] # Ch·ªâ l·∫•y c·ªôt c√≥ t·ªìn t·∫°i
        
        rename_map = {
            'legal_reference_filter': 'Lu·∫≠t L·ªá Li√™n quan (RAW-XX)',
            'action_type': 'T√≠nh ch·∫•t Bi·ªán ph√°p',
            'action_description': 'N·ªôi dung C√¥ng vi·ªác C·∫ßn l√†m',
            'evidence_of_completion': 'Minh ch·ª©ng Ho√†n th√†nh'
        }
        
        # B·∫£ng chi ti·∫øt
        st.dataframe(
            df_actions_filtered[action_cols].rename(columns=rename_map),
            use_container_width=True,
            height=500
        )

        st.markdown("""
            <div style='text-align: right; margin-top: 15px; font-style: italic; color: #555;'>
                *D·ªØ li·ªáu ƒëang hi·ªÉn th·ªã theo b·ªô l·ªçc ƒêi·ªÅu lu·∫≠t/Quy ƒë·ªãnh ƒë√£ ch·ªçn ·ªü sidebar.*
            </div>
        """, unsafe_allow_html=True)
