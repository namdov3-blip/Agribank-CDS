# python.py
# Streamlit app: Dashboard tr·ª±c quan h√≥a K·∫øt lu·∫≠n Thanh tra (KLTT)
# Ch·∫°y: streamlit run python.py
# Y√™u c·∫ßu c√†i ƒë·∫∑t:
#   pip install streamlit pandas altair openpyxl plotly requests google-generativeai

import io
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px
import requests  # TH√äM M·ªöI: Th∆∞ vi·ªán ƒë·ªÉ g·ªçi n8n Webhook

# === GEMINI CHAT (NEW) ===
try:
    import google.generativeai as genai
    _HAS_GEMINI = True
except Exception:
    _HAS_GEMINI = False

st.set_page_config(
    page_title="Dashboard K·∫øt lu·∫≠n Thanh tra (KLTT)",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==============================
# Helpers (GI·ªÆ NGUY√äN)
# ==============================

@st.cache_data(show_spinner=False)
def load_excel(uploaded_file: io.BytesIO) -> dict:
    xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
    sheets = {s.lower().strip(): s for s in xls.sheet_names}
    out = {}
    for canon, real in sheets.items():
        df = pd.read_excel(xls, real)
        df.columns = [str(c).strip() for c in df.columns]
        out[canon] = df
    return out

def canonicalize_df(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()
    new_cols = {}
    existing_lower = {c.lower(): c for c in df.columns}
    for want, aliases in mapping.items():
        for alias in aliases:
            if alias.lower() in existing_lower:
                new_cols[existing_lower[alias.lower()]] = want
                break
    return df.rename(columns=new_cols)

def coalesce_series_with_raw(series: pd.Series, prefix="RAW"):
    s = series.copy().astype(str)
    null_mask = s.isna() | s.str.strip().eq("") | s.str.lower().eq("nan")
    if null_mask.any():
        raw_index = np.cumsum(null_mask).where(null_mask, 0)
        s.loc[null_mask] = [f"{prefix}{i}" for i in raw_index[null_mask].astype(int)]
    return s

def to_number(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int, float, np.number)): return float(x)
    try:
        return float(str(x).replace(",", "").replace(" ", ""))
    except:
        digits = "".join(ch for ch in str(x) if (ch.isdigit() or ch=='.' or ch=='-'))
        try: return float(digits)
        except: return np.nan

def safe_date(series: pd.Series):
    try: return pd.to_datetime(series, errors="coerce")
    except Exception: return pd.to_datetime(pd.Series([None]*len(series)), errors="coerce")

def format_vnd(n):
    if pd.isna(n): return "‚Äî"
    n = float(n)
    if abs(n) >= 1_000_000_000_000: return f"{n/1_000_000_000_000:.2f} ngh√¨n t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000_000: return f"{n/1_000_000_000:.2f} t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000: return f"{n/1_000_000:.2f} tri·ªáu ‚Ç´"
    return f"{n:,.0f} ‚Ç´"

# ===== Plot helpers for Overalls (GI·ªÆ NGUY√äN) =====
PALETTE = ["#2563eb", "#16a34a", "#f59e0b", "#ef4444", "#0ea5e9", "#a855f7", "#22c55e", "#e11d48", "#6b7280"]

def _format_vnd_text(v):
    if pd.isna(v): return "‚Äî"
    try:
        v = float(v)
    except:
        return "‚Äî"
    if abs(v) < 0.5:
        return "0 ‚Ç´"
    return format_vnd(v)

def make_bar(df_in, x_col="Ch·ªâ ti√™u", y_col="Gi√° tr·ªã", title="", height=260):
    """Bar chart g·ªçn: m·ªói c·ªôt 1 m√†u; nh√£n in ƒë·∫≠m & ƒë·ªïi m√†u; hi·ªÉn th·ªã s·ªë 0."""
    d = df_in.copy()
    n = len(d)
    colors = PALETTE[:max(1, n)]
    fig = px.bar(
        d, x=x_col, y=y_col,
        text=d[y_col].apply(_format_vnd_text),
        color=x_col, color_discrete_sequence=colors,
        title=title
    )
    fig.update_traces(
        textposition="outside",
        texttemplate="<b>%{text}</b>",
        marker_line_color="white",
        marker_line_width=0.5,
        textfont=dict(color="#0ea5e9", size=12)
    )
    fig.update_layout(
        height=height, bargap=0.40,
        yaxis_title="VND", xaxis_title="", legend_title_text="",
        margin=dict(l=10, r=10, t=60, b=10)
    )
    return fig

def make_pie(labels_vals, title="", height=260):
    d = pd.DataFrame(labels_vals, columns=["Nh√≥m", "Gi√° tr·ªã"])
    d["Gi√° tr·ªã"] = d["Gi√° tr·ªã"].apply(lambda x: 0 if pd.isna(x) else float(x))
    fig = px.pie(
        d, names="Nh√≥m", values="Gi√° tr·ªã", hole=.35,
        color="Nh√≥m", color_discrete_sequence=PALETTE,
        title=title
    )
    fig.update_traces(textinfo="percent+label", textfont=dict(size=12), pull=[0.02]*len(d))
    fig.update_layout(height=height, margin=dict(l=10, r=10, t=60, b=10))
    return fig

# ==============================
# Theme + CSS (GI·ªÆ NGUY√äN)
# ==============================

st.markdown("""
<style>
:root { --label-color: #1f6feb; }
[data-testid="stDataFrame"] td, [data-testid="stDataFrame"] th {
    white-space: pre-wrap !important;
    word-break: break-word !important;
}
.info-card { padding: 10px 12px; border: 1px solid #e8e8e8; border-radius: 10px; background: #fff; min-height: 72px; }
.info-card .label { font-size: 12px; color: var(--label-color); font-weight: 700; margin-bottom: 4px; }
.info-card .value { font-size: 15px; line-height: 1.4; white-space: pre-wrap; word-break: break-word; }
.doc-wrap { padding: 10px 14px; border: 1px solid #e6e6e6; border-radius: 12px; background: #fafcff; margin-bottom: 14px; }
.doc-title { font-weight: 700; font-size: 16px; margin-bottom: 8px; }
</style>
""", unsafe_allow_html=True)

def info_card(label, value):
    if value in [None, np.nan, "nan", "None"]:
        value = "‚Äî"
    st.markdown(
        f"""
        <div class="info-card">
          <div class="label"><b>{label}</b></div>
          <div class="value">{value}</div>
        </div>
        """, unsafe_allow_html=True
    )

# ==============================
# RAG CHATBOT LOGIC (GI·ªÆ NGUY√äN + H√ÄM)
# ==============================

def call_n8n_rag_chatbot(prompt: str):
    """G·ª≠i c√¢u h·ªèi t·ªõi n8n RAG Webhook v√† nh·∫≠n c√¢u tr·∫£ l·ªùi. Bao g·ªìm logic Chat ID."""
    if "N8N_RAG_WEBHOOK_URL" not in st.secrets:
        return "L·ªói c·∫•u h√¨nh: Thi·∫øu N8N_RAG_WEBHOOK_URL trong secrets.toml. Vui l√≤ng thi·∫øt l·∫≠p ƒë·ªÉ s·ª≠ d·ª•ng chatbot."
    
    webhook_url = st.secrets["N8N_RAG_WEBHOOK_URL"]
    
    # Logic t·∫°o/l·∫•y Chat ID ƒë·ªÉ n8n qu·∫£n l√Ω b·ªô nh·ªõ (Simple Memory)
    if "chat_session_id" not in st.session_state:
        # T·∫°o ID duy nh·∫•t d·ª±a tr√™n timestamp
        st.session_state.chat_session_id = pd.Timestamp.now().strftime("%Y%m%d%H%M%S%f")

    payload = {
        "query": prompt,
        "chatId": st.session_state.chat_session_id  # Truy·ªÅn Chat ID
    }
    
    try:
        # TƒÉng timeout l√™n 90s ƒë·ªÉ tr√°nh l·ªói h·∫øt th·ªùi gian ch·ªù
        response = requests.post(webhook_url, json=payload, timeout=90)
        response.raise_for_status()
        data = response.json()
        
        return data.get("response", "Kh√¥ng t√¨m th·∫•y tr∆∞·ªùng 'response' trong ph·∫£n h·ªìi c·ªßa n8n. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh n8n.")

    except requests.exceptions.Timeout:
        return "RAG Chatbot (n8n) h·∫øt th·ªùi gian ch·ªù (Timeout: 90s). Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c r√∫t g·ªçn c√¢u h·ªèi."
    except requests.exceptions.RequestException as e:
        return f"L·ªói k·∫øt n·ªëi t·ªõi n8n: {e}. Vui l√≤ng ki·ªÉm tra URL Webhook v√† tr·∫°ng th√°i n8n."
    except Exception as e:
        return f"L·ªói x·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ n8n: {e}"

def reset_rag_chat_session():
    """H√†m n√†y s·∫Ω reset to√†n b·ªô l·ªãch s·ª≠ chat v√† session ID."""
    
    # 1. Reset l·ªãch s·ª≠ chat
    st.session_state.rag_chat_history = []
    
    # 2. Reset bi·∫øn ƒë·∫øm
    if "rag_chat_counter" in st.session_state:
        st.session_state.rag_chat_counter = 0

    # 3. Reset ID phi√™n chat (quan tr·ªçng ƒë·ªÉ n8n c≈©ng qu√™n l·ªãch s·ª≠)
    if "chat_session_id" in st.session_state:
        del st.session_state.chat_session_id
    
    # 4. Th√™m tin nh·∫Øn ch√†o m·ª´ng m·ªõi
    st.session_state.rag_chat_history.append(
        {"role": "assistant", "content": "Phi√™n tr√≤ chuy·ªán ƒë√£ ƒë∆∞·ª£c **reset** th√†nh c√¥ng. Ch√†o b·∫°n, t√¥i l√† Tr·ª£ l√Ω RAG ƒë∆∞·ª£c k·∫øt n·ªëi qua n8n. H√£y h·ªèi t√¥i v·ªÅ c√°c th√¥ng tin KLTT."}
    )
    
    # D√πng st.rerun() ƒë·ªÉ l√†m m·ªõi giao di·ªán ngay l·∫≠p t·ª©c
    st.rerun()

def rag_chat_tab():
    """Th√™m khung chat RAG k·∫øt n·ªëi qua n8n Webhook v√†o tab."""
    st.header("ü§ñ Tr·ª£ l√Ω RAG (H·ªèi & ƒê√°p D·ªØ li·ªáu KLTT)")
    
    # ƒê·∫∑t n√∫t Reset th·ªß c√¥ng
    if st.button("üîÑ B·∫Øt ƒë·∫ßu phi√™n Chat m·ªõi (Reset L·ªãch s·ª≠)", type="primary"):
        reset_rag_chat_session()
        return

    # 1. KH·ªûI T·∫†O BI·∫æN ƒê·∫æM & L·ªäCH S·ª¨ CHAT
    if "rag_chat_history" not in st.session_state:
        st.session_state.rag_chat_history = []
        st.session_state.rag_chat_counter = 0
        st.session_state.rag_chat_history.append(
            {"role": "assistant", "content": "Ch√†o b·∫°n, t√¥i l√† Tr·ª£ l√Ω RAG ƒë∆∞·ª£c k·∫øt n·ªëi qua n8n. H√£y h·ªèi t√¥i v·ªÅ c√°c th√¥ng tin KLTT."}
        )
    
    current_count = st.session_state.get("rag_chat_counter", 0)
    st.caption(f"Phi√™n chat hi·ªán t·∫°i: **{current_count}** / 5 c√¢u. (H·ªèi 5 c√¢u s·∫Ω t·ª± ƒë·ªông reset)")

    st.markdown("---")

    # Ki·ªÉm tra URL Webhook
    if "N8N_RAG_WEBHOOK_URL" not in st.secrets:
        st.warning("Vui l√≤ng thi·∫øt l·∫≠p N8N_RAG_WEBHOOK_URL trong file .streamlit/secrets.toml ƒë·ªÉ s·ª≠ d·ª•ng Chatbot.")
        return

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for message in st.session_state.rag_chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # 2. X·ª¨ L√ù INPUT V√Ä LOGIC RESET T·ª∞ ƒê·ªòNG
    if user_prompt := st.chat_input("H·ªèi Tr·ª£ l√Ω RAG...", key="rag_chat_input"):
        
        # KI·ªÇM TRA V√Ä RESET PHI√äN CHAT (T·ª± ƒë·ªông sau 5 c√¢u)
        if st.session_state.rag_chat_counter >= 5:
            with st.chat_message("assistant"):
                st.info("Phi√™n tr√≤ chuy·ªán ƒë√£ ƒë·∫°t 5 c√¢u h·ªèi. **L·ªãch s·ª≠ s·∫Ω ƒë∆∞·ª£c x√≥a.** Vui l√≤ng b·∫Øt ƒë·∫ßu c√¢u h·ªèi m·ªõi.")
            reset_rag_chat_session()
            return

        # 1. Th√™m prompt ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ v√† hi·ªÉn th·ªã ngay l·∫≠p t·ª©c
        st.session_state.rag_chat_history.append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(user_prompt)

        # 2. G·ªçi API n8n
        with st.chat_message("assistant"):
            with st.spinner("RAG Chatbot (n8n) ƒëang x·ª≠ l√Ω..."):
                response_text = call_n8n_rag_chatbot(user_prompt)
                st.markdown(response_text)
                # 3. C·∫≠p nh·∫≠t l·ªãch s·ª≠ chat v·ªõi c√¢u tr·∫£ l·ªùi V√Ä TƒÇNG BI·∫æN ƒê·∫æM
                st.session_state.rag_chat_history.append({"role": "assistant", "content": response_text})
                st.session_state.rag_chat_counter += 1

# ==============================
# GEMINI CHAT HELPERS (NEW)
# ==============================

def _setup_gemini():
    """
    Kh·ªüi t·∫°o model Gemini t·ª´ secrets.
    C·∫ßn th√™m v√†o .streamlit/secrets.toml:
    GEMINI_API_KEY = "your_key"
    # tu·ª≥ ch·ªçn:
    # GEMINI_MODEL = "gemini-1.5-flash" ho·∫∑c "gemini-1.5-pro"
    """
    if not _HAS_GEMINI:
        return None, "Ch∆∞a c√†i th∆∞ vi·ªán google-generativeai. Vui l√≤ng ch·∫°y: pip install google-generativeai"
    if "GEMINI_API_KEY" not in st.secrets:
        return None, "Thi·∫øu GEMINI_API_KEY trong secrets.toml"
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        model_name = st.secrets.get("GEMINI_MODEL", "gemini-1.5-flash")
        model = genai.GenerativeModel(model_name)
        return model, None
    except Exception as e:
        return None, f"L·ªói kh·ªüi t·∫°o Gemini: {e}"

def _call_gemini(model, user_msg: str, history: list):
    """
    G·ªçi Gemini k√®m ng·ªØ c·∫£nh (t·ªëi ƒëa 6 l∆∞·ª£t g·∫ßn nh·∫•t) ƒë·ªÉ h·ªôi tho·∫°i m∆∞·ª£t h∆°n.
    history: list[{'role': 'user'|'assistant', 'content': str}]
    """
    contents = []
    for h in history[-6:]:
        role = "user" if h["role"] == "user" else "model"
        contents.append({"role": role, "parts": [str(h["content"])[:6000]]})

    system_hint = (
        "B·∫°n l√† tr·ª£ l√Ω AI c·ªßa Agribank. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c, ∆∞u ti√™n ti·∫øng Vi·ªát, "
        "d√πng g·∫°ch ƒë·∫ßu d√≤ng n·∫øu c·∫ßn. N·∫øu c√¢u h·ªèi n·∫±m ngo√†i ph·∫°m vi, h√£y n√≥i r√µ v√† g·ª£i √Ω c√°ch h·ªèi ph√π h·ª£p."
    )
    contents.insert(0, {"role": "user", "parts": [system_hint]})
    contents.append({"role": "user", "parts": [user_msg[:6000]]})

    try:
        resp = model.generate_content(contents)
        return (resp.text or "").strip() if hasattr(resp, "text") else "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c n·ªôi dung ph·∫£n h·ªìi t·ª´ Gemini."
    except Exception as e:
        return f"L·ªói g·ªçi Gemini: {e}"

# ==============================
# Column mappings (GI·ªÆ NGUY√äN)
# ==============================

COL_MAP = {
    "documents": {
        "doc_id": ["Doc_id","doc_id","DocID","Maso"],
        "issue_date": ["Issue_date","Issues_date","issue_date"],
        "title": ["title","Title"],
        "issuing_authority": ["Issuing_authority","issuing_authority"],
        "inspected_entity_name": ["inspected_entity_name","Inspected_entity_name"],
        "sector": ["sector","Sector"],
        "period_start": ["period_start","Period_start"],
        "period_end": ["period_end","Period_end"],
        "signer_name": ["Signer_name","signer_name"],
        "signer_title": ["Signer_title","signer_title"],
    },
    "overalls": {
        "departments_at_hq_count": ["departments_at_hq_count"],
        "transaction_offices_count": ["transaction_offices_count"],
        "staff_total": ["staff_total"],
        "mobilized_capital_vnd": ["mobilized_capital_vnd"],
        "loans_outstanding_vnd": ["loans_outstanding_vnd"],
        "npl_total_vnd": ["npl_total_vnd"],
        "npl_ratio_percent": ["npl_ratio_percent"],
        "sample_total_files": ["sample_total_files"],
        "sample_outstanding_checked_vnd": ["sample_outstanding_checked_vnd"],

        # B·ªï sung theo y√™u c·∫ßu ph·∫ßn bi·ªÉu ƒë·ªì
        "structure_quality_group1_vnd": ["structure_quality_group1_vnd"],
        "structure_quality_group2_vnd": ["structure_quality_group2_vnd"],
        "structure_quality_group3_vnd": ["structure_quality_group3_vnd"],

        "structure_term_short_vnd": ["structure_term_short_vnd"],
        "structure_term_medium_long_vnd": ["structure_term_medium_long_vnd"],

        "structure_currency_vnd_vnd": ["structure_currency_vnd_vnd"],
        "structure_currency_fx_vnd": ["structure_currency_fx_vnd"],

        "structure_purpose_bds_flexible_vnd": ["structure_purpose_bds_flexible_vnd"],
        "strucuture_purpose_securities_vnd": ["strucuture_purpose_securities_vnd"],
        "structure_purpose_consumption_vnd": ["structure_purpose_consumption_vnd"],
        "structure_purpose_trade_vnd": ["structure_purpose_trade_vnd"],
        "structure_purpose_other_vnd": ["structure_purpose_other_vnd"],

        "strucuture_econ_state_vnd": ["strucuture_econ_state_vnd"],
        "strucuture_econ_nonstate_enterprises_vnd": ["strucuture_econ_nonstate_enterprises_vnd"],
        "strucuture_econ_individuals_households_vnd": ["strucuture_econ_individuals_households_vnd"],
    },
    "findings": {
        "category": ["category"],
        "sub_category": ["sub_category"],
        "description": ["description"],
        "legal_reference": ["legal_reference"],
        "quantified_amount": ["quantified_amount"],
        "impacted_accounts": ["impacted_accounts"],
        "root_cause": ["Root_cause","root_cause"],
        "recommendation": ["recommendation"],
    },
    "actions": {
        "action_type": ["action_type"],
        "legal_reference": ["legal_reference"],
        "action_description": ["action_description"],
        "evidence_of_completion": ["evidence_of_completion"],
    }
}

# ==============================
# Sidebar (Upload + Gemini Chat) (ƒê√É CH√àN CHAT GEMINI)
# ==============================

with st.sidebar:
    st.header("üì§ T·∫£i d·ªØ li·ªáu")
    uploaded = st.file_uploader("Excel (.xlsx): documents, overalls, findings, (actions tu·ª≥ ch·ªçn)", type=["xlsx"])
    st.caption("T√™n sheet & c·ªôt kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng.")

    # === GEMINI CHAT SIDEBAR (NEW) ===
    st.markdown("---")
    with st.expander("üí¨ Gemini Chat (beta)", expanded=False):
        model, gem_err = _setup_gemini()

        # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat l∆∞u trong session
        if "gem_chat_history" not in st.session_state:
            st.session_state.gem_chat_history = [
                {"role": "assistant", "content": "Xin ch√†o! T√¥i l√† Gemini ‚Äì tr·ª£ l√Ω AI h·ªó tr·ª£ b·∫°n trong thi·∫øt k·∫ø s·∫£n ph·∫©m AI/Chuy·ªÉn ƒë·ªïi s·ªë Agribank. B·∫°n mu·ªën h·ªèi g√¨?"}
            ]

        # Hi·ªÉn th·ªã l·ªãch s·ª≠ t√≥m t·∫Øt (sidebar kh√¥ng h·ªó tr·ª£ st.chat_message, d√πng markdown)
        hist_container = st.container()
        for m in st.session_state.gem_chat_history[-8:]:
            who = "üë§ B·∫°n" if m["role"] == "user" else "ü§ñ Gemini"
            hist_container.markdown(f"**{who}:** {m['content']}")

        # Input + Buttons
        user_msg = st.text_input("Nh·∫≠p c√¢u h·ªèi cho Gemini...", key="gem_input")
        c1, c2 = st.columns(2)
        send_clicked = c1.button("G·ª≠i", use_container_width=True, disabled=(not user_msg))
        reset_clicked = c2.button("Reset", use_container_width=True)

        if reset_clicked:
            st.session_state.gem_chat_history = [
                {"role": "assistant", "content": "ƒê√£ t·∫°o phi√™n m·ªõi. T√¥i l√† Gemini, s·∫µn s√†ng h·ªó tr·ª£ b·∫°n!"}
            ]
            st.rerun()

        if send_clicked and user_msg:
            if gem_err:
                st.warning(gem_err)
            elif model is None:
                st.warning("Gemini ch∆∞a s·∫µn s√†ng.")
            else:
                # L∆∞u c√¢u h·ªèi
                st.session_state.gem_chat_history.append({"role": "user", "content": user_msg})
                with st.spinner("Gemini ƒëang tr·∫£ l·ªùi..."):
                    answer = _call_gemini(model, user_msg, st.session_state.gem_chat_history)
                st.session_state.gem_chat_history.append({"role": "assistant", "content": answer})
                st.rerun()

st.title("üõ°Ô∏è Dashboard B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra")

if not uploaded:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

# ... (Ti·∫øp t·ª•c x·ª≠ l√Ω d·ªØ li·ªáu)

data = load_excel(uploaded)

def get_df(sheet_key):
    raw = data.get(sheet_key)
    mapping = COL_MAP.get(sheet_key, {})
    if raw is None: return pd.DataFrame()
    return canonicalize_df(raw.copy(), mapping)

df_docs = get_df("documents")
df_over = get_df("overalls")
df_find = get_df("findings")
df_act = get_df("actions")

if df_docs.empty or df_over.empty or df_find.empty:
    st.error("Thi·∫øu m·ªôt trong c√°c sheet b·∫Øt bu·ªôc: documents, overalls, findings.")
    st.stop()

# Dates
for c in ["issue_date","period_start","period_end"]:
    if c in df_docs.columns:
        df_docs[c] = safe_date(df_docs[c])

# Numeric
for c in COL_MAP["overalls"].keys():
    if c in df_over.columns: df_over[c] = df_over[c].apply(to_number)
for c in ["quantified_amount","impacted_accounts"]:
    if c in df_find.columns: df_find[c] = df_find[c].apply(to_number)

# RAW handling
df_find["legal_reference_filter"] = coalesce_series_with_raw(df_find["legal_reference"], prefix="RAW")
df_find["legal_reference_chart"] = df_find["legal_reference_filter"].apply(lambda x: "RAW" if str(x).startswith("RAW") else x)

# Sidebar filter (findings only) (GI·ªÆ NGUY√äN)
with st.sidebar:
    st.header("üîé L·ªçc Findings")
    all_refs = sorted(df_find["legal_reference_filter"].astype(str).unique().tolist())
    selected_refs = st.multiselect("Ch·ªçn Legal_reference", options=all_refs, default=all_refs)
    f_df = df_find[df_find["legal_reference_filter"].astype(str).isin([str(x) for x in selected_refs])].copy()

    st.markdown("---")
    st.metric("üí∏ T·ªïng ti·ªÅn ·∫£nh h∆∞·ªüng (l·ªçc)", format_vnd(f_df["quantified_amount"].sum()))
    st.metric("üë• T·ªïng h·ªì s∆° ·∫£nh h∆∞·ªüng (l·ªçc)", f"{int(f_df['impacted_accounts'].sum()) if 'impacted_accounts' in f_df.columns and pd.notna(f_df['impacted_accounts'].sum()) else '‚Äî'}")

# ==============================
# Tabs (ƒê√É TH√äM TAB CHATBOT)
# ==============================

# TH√äM 'ü§ñ Chatbot' V√ÄO DANH S√ÅCH TABS
tab_docs, tab_over, tab_find, tab_act, tab_chat = st.tabs(["üìù Documents","üìä Overalls","üö® Findings","‚úÖ Actions", "ü§ñ Chatbot"])

# ---- Chatbot Tab (G·ªåI H√ÄM M·ªöI) ----
with tab_chat:
    rag_chat_tab()

# ---- Documents (GI·ªÆ NGUY√äN) ----
with tab_docs:
    st.header("B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra (Metadata)")
    st.markdown("---")
    if len(df_docs) == 0:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu documents.")
    else:
        for idx, row in df_docs.reset_index(drop=True).iterrows():
            st.markdown(f'<div class="doc-wrap"><div class="doc-title">üìù B√°o c√°o k·∫øt lu·∫≠n thanh tra ‚Äî {str(row.get("doc_id","‚Äî"))}</div>', unsafe_allow_html=True)
            c1, c2, c3, c4 = st.columns(4)
            with c1:
                info_card("M√£ s·ªë k·∫øt lu·∫≠n thanh tra (Doc_id)", str(row.get("doc_id","‚Äî")))
                info_card("ƒê∆°n v·ªã ph√°t h√†nh (Issuing_authority)", str(row.get("issuing_authority","‚Äî")))
                info_card("Ng∆∞·ªùi ki·ªÉm so√°t (Signer_name)", str(row.get("signer_name","‚Äî")))
            with c2:
                d = row.get("issue_date", pd.NaT)
                info_card("Ng√†y ph√°t h√†nh (Issue_date)", d.strftime("%d/%m/%Y") if pd.notna(d) else "‚Äî")
                info_card("ƒê∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm tra (inspected_entity_name)", str(row.get("inspected_entity_name","‚Äî")))
                info_card("Ch·ª©c v·ª• (Signer_title)", str(row.get("signer_title","‚Äî")))
            with c3:
                info_card("Title", str(row.get("title","‚Äî")))
                info_card("Lƒ©nh v·ª±c (sector)", str(row.get("sector","‚Äî")))
            with c4:
                ps = row.get("period_start", pd.NaT); pe = row.get("period_end", pd.NaT)
                info_card("Th·ªùi gian b·∫Øt ƒë·∫ßu (period_start)", ps.strftime("%d/%m/%Y") if pd.notna(ps) else "‚Äî")
                info_card("Th·ªùi gian k·∫øt th√∫c (period_end)", pe.strftime("%d/%m/%Y") if pd.notna(pe) else "‚Äî")
            st.markdown("</div>", unsafe_allow_html=True)

# ---- Overalls (GI·ªÆ NGUY√äN) ----
with tab_over:
    st.header("Th√¥ng Tin T·ªïng Quan")
    st.markdown("---")
    over_row = df_over.iloc[-1] if len(df_over) else pd.Series({})

    # KPIs s∆° l∆∞·ª£c
    k1,k2,k3,k4,k5 = st.columns(5)
    with k1:
        st.metric("T·ªïng nh√¢n s·ª±", f"{int(over_row.get('staff_total', np.nan)) if pd.notna(over_row.get('staff_total', np.nan)) else '‚Äî'}")
        st.metric("M·∫´u ki·ªÉm tra", f"{int(over_row.get('sample_total_files', np.nan)) if pd.notna(over_row.get('sample_total_files', np.nan)) else '‚Äî'}")
    with k2:
        st.metric("Ph√≤ng nghi·ªáp v·ª• (HQ)", f"{int(over_row.get('departments_at_hq_count', np.nan)) if pd.notna(over_row.get('departments_at_hq_count', np.nan)) else '‚Äî'}")
        st.metric("Ph√≤ng giao d·ªãch", f"{int(over_row.get('transaction_offices_count', np.nan)) if pd.notna(over_row.get('transaction_offices_count', np.nan)) else '‚Äî'}")
    with k3:
        st.metric("Ngu·ªìn v·ªën g·∫ßn nh·∫•t", format_vnd(over_row.get("mobilized_capital_vnd", np.nan)))
    with k4:
        st.metric("D∆∞ n·ª£ g·∫ßn nh·∫•t", format_vnd(over_row.get("loans_outstanding_vnd", np.nan)))
    with k5:
        st.metric("N·ª£ x·∫•u (nh√≥m 3-5)", format_vnd(over_row.get("npl_total_vnd", np.nan)))
        st.metric("T·ª∑ l·ªá NPL / D∆∞ n·ª£", f"{over_row.get('npl_ratio_percent', np.nan):.2f}%" if pd.notna(over_row.get('npl_ratio_percent', np.nan)) else "‚Äî")
        st.metric("T·ªïng d∆∞ n·ª£ ƒë√£ ki·ªÉm tra", format_vnd(over_row.get("sample_outstanding_checked_vnd", np.nan)))

    st.markdown("---")

    # 1) Ch·∫•t l∆∞·ª£ng t√≠n d·ª•ng Nh√≥m 1‚Äì3 (Bar + Pie)
    st.subheader("**Ch·∫•t l∆∞·ª£ng t√≠n d·ª•ng (Nh√≥m 1‚Äì3)**")
    q_items = [
        ("Nh√≥m 1", "structure_quality_group1_vnd"),
        ("Nh√≥m 2", "structure_quality_group2_vnd"),
        ("Nh√≥m 3", "structure_quality_group3_vnd"),
    ]
    q_data = []
    for n, c in q_items:
        val = over_row.get(c, np.nan) if c in df_over.columns else np.nan
        val = 0 if pd.isna(val) else float(val)
        q_data.append({"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": val})
    dfq = pd.DataFrame(q_data)
    c1, c2 = st.columns([2,1])
    with c1:
        fig_q_bar = make_bar(dfq, title="Bar: Quy m√¥ theo nh√≥m (nh√£n ƒë·∫≠m & ƒë·ªïi m√†u)")
        st.plotly_chart(fig_q_bar, use_container_width=True)
    with c2:
        fig_q_pie = make_pie([(r["Ch·ªâ ti√™u"], r["Gi√° tr·ªã"]) for _, r in dfq.iterrows()], title="Pie: C∆° c·∫•u t·ª∑ tr·ªçng")
        st.plotly_chart(fig_q_pie, use_container_width=True)

    # 2) K·ª≥ h·∫°n
    st.subheader("**C∆° c·∫•u theo k·ª≥ h·∫°n**")
    term_items = [
        ("D∆∞ n·ª£ ng·∫Øn h·∫°n", "structure_term_short_vnd"),
        ("D∆∞ n·ª£ trung & d√†i h·∫°n", "structure_term_medium_long_vnd"),
    ]
    term_data = []
    for n, c in term_items:
        val = over_row.get(c, np.nan) if c in df_over.columns else np.nan
        term_data.append({"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": 0 if pd.isna(val) else float(val)})
    dft = pd.DataFrame(term_data)
    fig_t = make_bar(dft, title="K·ª≥ h·∫°n (bar nh·ªè, m·ªói c·ªôt 1 m√†u)")
    st.plotly_chart(fig_t, use_container_width=True)

    # 3) Ti·ªÅn t·ªá
    st.subheader("**C∆° c·∫•u theo ti·ªÅn t·ªá**")
    cur_items = [
        ("D∆∞ n·ª£ b·∫±ng VND", "structure_currency_vnd_vnd"),
        ("D∆∞ n·ª£ quy ƒë·ªïi ngo·∫°i t·ªá", "structure_currency_fx_vnd"),
    ]
    cur_data = []
    for n, c in cur_items:
        val = over_row.get(c, np.nan) if c in df_over.columns else np.nan
        cur_data.append({"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": 0 if pd.isna(val) else float(val)})
    dfc = pd.DataFrame(cur_data)
    fig_c = make_bar(dfc, title="Ti·ªÅn t·ªá (bar nh·ªè, nh√£n ƒë·∫≠m & m√†u)")
    st.plotly_chart(fig_c, use_container_width=True)

    # 4) M·ª•c ƒë√≠ch vay
    st.subheader("**C∆° c·∫•u theo m·ª•c ƒë√≠ch vay**")
    pur_items = [
        ("BƒêS / linh ho·∫°t", "structure_purpose_bds_flexible_vnd"),
        ("Ch·ª©ng kho√°n", "strucuture_purpose_securities_vnd"),
        ("Ti√™u d√πng", "structure_purpose_consumption_vnd"),
        ("Th∆∞∆°ng m·∫°i", "structure_purpose_trade_vnd"),
        ("M·ª•c ƒë√≠ch kh√°c", "structure_purpose_other_vnd"),
    ]
    pur_data = []
    for n, c in pur_items:
        val = over_row.get(c, np.nan) if c in df_over.columns else np.nan
        pur_data.append({"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": 0 if pd.isna(val) else float(val)})
    dfp = pd.DataFrame(pur_data)
    fig_p = make_bar(dfp, title="M·ª•c ƒë√≠ch vay (bar nh·ªè)")
    st.plotly_chart(fig_p, use_container_width=True)

    # 5) Th√†nh ph·∫ßn kinh t·∫ø (lu√¥n hi·ªÉn th·ªã c·∫£ 0)
    st.subheader("**C∆° c·∫•u theo th√†nh ph·∫ßn kinh t·∫ø**")
    eco_items = [
        ("DN Nh√† n∆∞·ªõc", "strucuture_econ_state_vnd"),
        ("DN t·ªï ch·ª©c kinh t·∫ø", "strucuture_econ_nonstate_enterprises_vnd"),
        ("DN t∆∞ nh√¢n c√° th·ªÉ", "strucuture_econ_individuals_households_vnd"),
    ]
    eco_data = []
    for n, c in eco_items:
        val = over_row.get(c, np.nan) if c in df_over.columns else np.nan
        eco_data.append({"Ch·ªâ ti√™u": n, "Gi√° tr·ªã": 0 if pd.isna(val) else float(val)})
    dfe = pd.DataFrame(eco_data)
    fig_e = make_bar(dfe, title="Th√†nh ph·∫ßn kinh t·∫ø (bar nh·ªè, hi·ªÉn th·ªã 0)")
    st.plotly_chart(fig_e, use_container_width=True)

# ---- Findings (GI·ªÆ NGUY√äN) ----
with tab_find:
    st.header("Ph√°t hi·ªán & Nguy√™n nh√¢n (Findings)")
    st.subheader(f"ƒêang l·ªçc theo: {len(selected_refs)}/{len(all_refs)} legal_reference")
    st.markdown("---")
    if f_df.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu theo b·ªô l·ªçc hi·ªán t·∫°i.")
    else:
        col1, col2 = st.columns(2)
        with col1:
            cat_count = f_df["category"].value_counts().reset_index()
            cat_count.columns = ["Category","Count"]
            fig1 = px.bar(cat_count, x="Category", y="Count", text="Count", color="Category",
                          title="S·ªë l·∫ßn xu·∫•t hi·ªán theo Category")
            fig1.update_traces(textposition="outside")
            fig1.update_layout(height=380, xaxis_title="", yaxis_title="S·ªë l·∫ßn")
            st.plotly_chart(fig1, use_container_width=True)
        with col2:
            cat_sub = f_df.groupby(["category","sub_category"]).size().reset_index(name="Count")
            fig2 = px.bar(cat_sub, x="category", y="Count", color="sub_category",
                          title="Category √ó Sub_category (s·ªë l·∫ßn)", barmode="group",
                          labels={"category":"Category","sub_category":"Sub_category","Count":"S·ªë l·∫ßn"})
            fig2.update_layout(height=380)
            st.plotly_chart(fig2, use_container_width=True)

        st.markdown("---")
        st.subheader("Xu h∆∞·ªõng theo Legal_reference (g·ªôp RAWx ‚Üí RAW)")
        legal_count = f_df["legal_reference_chart"].value_counts().reset_index()
        legal_count.columns = ["Legal_reference","Count"]
        fig3 = px.line(legal_count, x="Legal_reference", y="Count", markers=True,
                       title="S·ªë l·∫ßn xu·∫•t hi·ªán theo Legal_reference (g·ªôp RAWx‚ÜíRAW)")
        st.plotly_chart(fig3, use_container_width=True)
        st.info("RAW = lu·∫≠t/quy ƒë·ªãnh kh√¥ng ƒë∆∞·ª£c nh·∫Øc t·ªõi; √¥ tr·ªëng ƒë√£ g√°n RAW1, RAW2‚Ä¶ v√† g·ªôp th√†nh RAW cho bi·ªÉu ƒë·ªì.")

        st.markdown("---")
        st.subheader("T·∫ßn su·∫•t t·ª´ng Legal_reference (kh√¥ng g·ªôp ph·ª• l·ª•c/ƒëi·ªÉm kho·∫£n)")
        freq_tbl = f_df["legal_reference_filter"].value_counts().reset_index()
        freq_tbl.columns = ["Legal_reference","S·ªë l·∫ßn"]
        st.dataframe(freq_tbl, use_container_width=True, height=320)

        st.markdown("---")
        st.subheader("Chi ti·∫øt theo t·ª´ng Sub_category")
        order_sub = f_df["sub_category"].value_counts().index.tolist()
        for sub in order_sub:
            st.markdown(f"#### üîπ {sub}")
            sub_df = f_df[f_df["sub_category"]==sub].copy()
            sub_df["legal_reference"] = sub_df["legal_reference_filter"]
            cols_show = [c for c in ["description","legal_reference","quantified_amount","impacted_accounts","root_cause"] if c in sub_df.columns]
            sub_df = sub_df[cols_show]
            if "quantified_amount" in sub_df.columns:
                sub_df["quantified_amount"] = sub_df["quantified_amount"].apply(format_vnd)
            if "impacted_accounts" in sub_df.columns:
                sub_df["impacted_accounts"] = sub_df["impacted_accounts"].apply(lambda x: f"{int(x):,}" if pd.notna(x) else "‚Äî")
            rename = {
                "description":"M√¥ t·∫£",
                "legal_reference":"ƒêi·ªÅu lu·∫≠t/Quy ƒë·ªãnh",
                "quantified_amount":"S·ªë ti·ªÅn ·∫£nh h∆∞·ªüng",
                "impacted_accounts":"S·ªë KH/H·ªì s∆°",
                "root_cause":"Nguy√™n nh√¢n g·ªëc"
            }
            st.dataframe(sub_df.rename(columns=rename), use_container_width=True)

        st.markdown("---")
        st.subheader("Ph√¢n t√≠ch theo b·ªô lu·∫≠t")
        tmp = f_df.copy()
        tmp["legal_reference"] = tmp["legal_reference_filter"]
        cols = ["legal_reference"]
        if "root_cause" in tmp.columns: cols.append("root_cause")
        if "recommendation" in tmp.columns: cols.append("recommendation")
        law_tbl = tmp[cols].drop_duplicates().reset_index(drop=True)
        law_tbl = law_tbl.rename(columns={
            "legal_reference":"Legal_reference",
            "root_cause":"Root_cause",
            "recommendation":"Recommendation"
        })
        st.dataframe(law_tbl, use_container_width=True)

# ---- Actions (GI·ªÆ NGUY√äN) ----
with tab_act:
    st.header("Bi·ªán ph√°p kh·∫Øc ph·ª•c (Actions)")
    st.markdown("---")
    if df_act is None or df_act.empty:
        st.info("Kh√¥ng c√≥ sheet actions ho·∫∑c thi·∫øu c·ªôt. C·∫ßn: action_type, legal_reference, action_description, evidence_of_completion.")
    else:
        df_act_full = df_act.copy()
        df_act_full["Legal_reference"] = coalesce_series_with_raw(df_act_full["legal_reference"], prefix="RAW")
        # Chart
        if "action_type" in df_act_full.columns:
            act_count = df_act_full["action_type"].value_counts().reset_index()
            act_count.columns = ["Action_type","Count"]
            fig = px.pie(act_count, values="Count", names="Action_type", title="Ph√¢n lo·∫°i t√≠nh ch·∫•t bi·ªán ph√°p", hole=.35)
            fig.update_traces(textinfo="percent+label")
            st.plotly_chart(fig, use_container_width=True)
        st.markdown("---")
        # Table (all rows)
        cols = [c for c in ["Legal_reference","action_type","action_description","evidence_of_completion"] if c in df_act_full.columns or c=="Legal_reference"]
        rename = {
            "action_type":"T√≠nh ch·∫•t bi·ªán ph√°p",
            "action_description":"N·ªôi dung c√¥ng vi·ªác ph·∫£i l√†m",
            "evidence_of_completion":"C√¥ng vi·ªác chi ti·∫øt / Minh ch·ª©ng"
        }
        st.dataframe(df_act_full[cols].rename(columns=rename), use_container_width=True, height=500)

st.caption("¬© KLTT Dashboard ‚Ä¢ Streamlit ‚Ä¢ Altair ‚Ä¢ Plotly ‚Ä¢ Gemini (sidebar) ‚Ä¢ n8n RAG (tab)")
