# python.py
# Streamlit app: Dashboard tr·ª±c quan h√≥a K·∫øt lu·∫≠n Thanh tra (KLTT)
# Ch·∫°y: streamlit run python.py
# Y√™u c·∫ßu: pip install streamlit pandas altair openpyxl plotly google-genai

import io
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px
# Th√™m th∆∞ vi·ªán Google GenAI
from google import genai
from google.genai import types

st.set_page_config(
    page_title="Dashboard K·∫øt lu·∫≠n Thanh tra (KLTT)",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==============================
# Helpers
# ==============================

@st.cache_data(show_spinner=False)
def load_excel(uploaded_file: io.BytesIO) -> dict:
    xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
    sheets = {s.lower().strip(): s for s in xls.sheet_names}
    out = {}
    for canon, real in sheets.items():
        df = pd.read_excel(xls, real)
        df.columns = [str(c).strip() for c in df.columns]
        out[canon] = df
    return out

def canonicalize_df(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()
    new_cols = {}
    existing_lower = {c.lower(): c for c in df.columns}
    for want, aliases in mapping.items():
        for alias in aliases:
            if alias.lower() in existing_lower:
                new_cols[existing_lower[alias.lower()]] = want
                break
    return df.rename(columns=new_cols)

def coalesce_series_with_raw(series: pd.Series, prefix="RAW"):
    s = series.copy()
    s = s.astype(str)
    null_mask = s.isna() | s.str.strip().eq("") | s.str.lower().eq("nan")
    if null_mask.any():
        raw_index = np.cumsum(null_mask).where(null_mask, 0)
        s.loc[null_mask] = [f"{prefix}{i}" for i in raw_index[null_mask].astype(int)]
    return s

def to_number(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int, float, np.number)): return float(x)
    try: return float(str(x).replace(",", "").replace(" ", ""))
    except:
        digits = "".join(ch for ch in str(x) if (ch.isdigit() or ch=='.' or ch=='-'))
        try: return float(digits)
        except: return np.nan

def safe_date(series: pd.Series):
    try: return pd.to_datetime(series, errors="coerce")
    except Exception: return pd.to_datetime(pd.Series([None]*len(series)), errors="coerce")

def format_vnd(n):
    if pd.isna(n): return "‚Äî"
    n = float(n)
    if abs(n) >= 1_000_000_000_000: return f"{n/1_000_000_000_000:.2f} ngh√¨n t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000_000:       return f"{n/1_000_000_000:.2f} t·ª∑ ‚Ç´"
    if abs(n) >= 1_000_000:           return f"{n/1_000_000:.2f} tri·ªáu ‚Ç´"
    return f"{n:,.0f} ‚Ç´"

# ==============================
# Theme + CSS
# ==============================

st.markdown("""
<style>
:root { --label-color: #1f6feb; }
[data-testid="stDataFrame"] td, [data-testid="stDataFrame"] th {
    white-space: pre-wrap !important;
    word-break: break-word !important;
}
.info-card { padding: 10px 12px; border: 1px solid #e8e8e8; border-radius: 10px; background: #fff; min-height: 72px; }
.info-card .label { font-size: 12px; color: var(--label-color); font-weight: 700; margin-bottom: 4px; }
.info-card .value { font-size: 15px; line-height: 1.4; white-space: pre-wrap; word-break: break-word; }
.doc-wrap { padding: 10px 14px; border: 1px solid #e6e6e6; border-radius: 12px; background: #fafcff; margin-bottom: 14px; }
.doc-title { font-weight: 700; font-size: 16px; margin-bottom: 8px; }
</style>
""", unsafe_allow_html=True)

def info_card(label, value):
    if value in [None, np.nan, "nan", "None"]:
        value = "‚Äî"
    st.markdown(
        f"""
        <div class="info-card">
          <div class="label"><b>{label}</b></div>
          <div class="value">{value}</div>
        </div>
        """, unsafe_allow_html=True
    )

# ==============================
# Column mappings
# ==============================

COL_MAP = {
    "documents": {
        "doc_id": ["Doc_id","doc_id","DocID","Maso"],
        "issue_date": ["Issue_date","Issues_date","issue_date"],
        "title": ["title","Title"],
        "issuing_authority": ["Issuing_authority","issuing_authority"],
        "inspected_entity_name": ["inspected_entity_name","Inspected_entity_name"],
        "sector": ["sector","Sector"],
        "period_start": ["period_start","Period_start"],
        "period_end": ["period_end","Period_end"],
        "signer_name": ["Signer_name","signer_name"],
        "signer_title": ["Signer_title","signer_title"],
    },
    "overalls": {
        "departments_at_hq_count": ["departments_at_hq_count"],
        "transaction_offices_count": ["transaction_offices_count"],
        "staff_total": ["staff_total"],
        "mobilized_capital_vnd": ["mobilized_capital_vnd"],
        "loans_outstanding_vnd": ["loans_outstanding_vnd"],
        "npl_total_vnd": ["npl_total_vnd"],
        "npl_ratio_percent": ["npl_ratio_percent"],
        "sample_total_files": ["sample_total_files"],
        "sample_outstanding_checked_vnd": ["sample_outstanding_checked_vnd"],
    },
    "findings": {
        "category": ["category"],
        "sub_category": ["sub_category"],
        "description": ["description"],
        "legal_reference": ["legal_reference"],
        "quantified_amount": ["quantified_amount"],
        "impacted_accounts": ["impacted_accounts"],
        "root_cause": ["Root_cause","root_cause"],
        "recommendation": ["recommendation"],
    },
    "actions": {
        "action_type": ["action_type"],
        "legal_reference": ["legal_reference"],
        "action_description": ["action_description"],
        "evidence_of_completion": ["evidence_of_completion"],
    }
}


# ==============================
# Sidebar (Upload + Filters)
# ==============================

# Khai b√°o/Kh·ªüi t·∫°o c√°c bi·∫øn DataFrame ·ªü ph·∫°m vi to√†n c·ª•c (TR∆Ø·ªöC khi g·ªçi h√†m gemini_chat_sidebar() l·∫ßn ƒë·∫ßu)
df_docs = pd.DataFrame()
df_over = pd.DataFrame()
df_find = pd.DataFrame()
df_act  = pd.DataFrame()
f_df = pd.DataFrame()
all_refs = []
selected_refs = []


with st.sidebar:
    st.header("üì§ T·∫£i d·ªØ li·ªáu")
    uploaded = st.file_uploader("Excel (.xlsx): documents, overalls, findings, (actions tu·ª≥ ch·ªçn)", type=["xlsx"])
    st.caption("T√™n sheet & c·ªôt kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng.")

st.title("üõ°Ô∏è Dashboard B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra")

if not uploaded:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    # --- [GEMINI CHAT] ---
    st.sidebar.markdown("---")
    # L∆ØU √ù: L·∫ßn g·ªçi n√†y s·∫Ω s·ª≠ d·ª•ng c√°c DataFrame r·ªóng ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o ·ªü tr√™n
    gemini_chat_sidebar(df_docs, df_over, df_find, df_act, f_df, True) 
    # ---------------------
    st.stop()

# --- CODE CH·ªà CH·∫†Y KHI C√ì FILE ƒê∆Ø·ª¢C UPLOAD ---

data = load_excel(uploaded)

def get_df(sheet_key):
    raw = data.get(sheet_key)
    mapping = COL_MAP.get(sheet_key, {})
    if raw is None: return pd.DataFrame()
    return canonicalize_df(raw.copy(), mapping)

df_docs = get_df("documents")
df_over = get_df("overalls")
df_find = get_df("findings")
df_act  = get_df("actions")

if df_docs.empty or df_over.empty or df_find.empty:
    st.error("Thi·∫øu m·ªôt trong c√°c sheet b·∫Øt bu·ªôc: documents, overalls, findings.")
    # --- [GEMINI CHAT] ---
    st.sidebar.markdown("---")
    gemini_chat_sidebar(df_docs, df_over, df_find, df_act, f_df, True)
    # ---------------------
    st.stop()

# Dates
for c in ["issue_date","period_start","period_end"]:
    if c in df_docs.columns:
        df_docs[c] = safe_date(df_docs[c])

# Numeric
for c in COL_MAP["overalls"].keys():
    if c in df_over.columns: df_over[c] = df_over[c].apply(to_number)
for c in ["quantified_amount","impacted_accounts"]:
    if c in df_find.columns: df_find[c] = df_find[c].apply(to_number)

# RAW handling
df_find["legal_reference_filter"] = coalesce_series_with_raw(df_find["legal_reference"], prefix="RAW")
df_find["legal_reference_chart"] = df_find["legal_reference_filter"].apply(lambda x: "RAW" if str(x).startswith("RAW") else x)

# Sidebar filter (findings only)
st.sidebar.header("üîé L·ªçc Findings")
all_refs = sorted(df_find["legal_reference_filter"].astype(str).unique().tolist())
selected_refs = st.sidebar.multiselect("Ch·ªçn Legal_reference", options=all_refs, default=all_refs)
f_df = df_find[df_find["legal_reference_filter"].astype(str).isin([str(x) for x in selected_refs])].copy()

st.sidebar.markdown("---")
st.sidebar.metric("üí∏ T·ªïng ti·ªÅn ·∫£nh h∆∞·ªüng (l·ªçc)", format_vnd(f_df["quantified_amount"].sum()))
st.sidebar.metric("üë• T·ªïng h·ªì s∆° ·∫£nh h∆∞·ªüng (l·ªçc)", f"{int(f_df['impacted_accounts'].sum()) if 'impacted_accounts' in f_df.columns and pd.notna(f_df['impacted_accounts'].sum()) else '‚Äî'}")

# --- [GEMINI CHAT] ---
# L·∫ßn g·ªçi n√†y s·ª≠ d·ª•ng c√°c DataFrame ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅn d·ªØ li·ªáu
gemini_chat_sidebar(df_docs, df_over, df_find, df_act, f_df, False)
# ---------------------

# ==============================
# Tabs
# ==============================

tab_docs, tab_over, tab_find, tab_act = st.tabs(["üìù Documents","üìä Overalls","üö® Findings","‚úÖ Actions"])

# ---- Documents (no dropdown; render all docs) ----
with tab_docs:
    st.header("B√°o C√°o K·∫øt Lu·∫≠n Thanh Tra (Metadata)")
    st.markdown("---")
    if len(df_docs) == 0:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu documents.")
    else:
        for idx, row in df_docs.reset_index(drop=True).iterrows():
            st.markdown(f'<div class="doc-wrap"><div class="doc-title">üìù B√°o c√°o k·∫øt lu·∫≠n thanh tra ‚Äî {str(row.get("doc_id","‚Äî"))}</div>', unsafe_allow_html=True)
            c1, c2, c3, c4 = st.columns(4)
            with c1:
                info_card("M√£ s·ªë k·∫øt lu·∫≠n thanh tra (Doc_id)", str(row.get("doc_id","‚Äî")))
                info_card("ƒê∆°n v·ªã ph√°t h√†nh (Issuing_authority)", str(row.get("issuing_authority","‚Äî")))
                info_card("Ng∆∞·ªùi ki·ªÉm so√°t (Signer_name)", str(row.get("signer_name","‚Äî")))
            with c2:
                d = row.get("issue_date", pd.NaT)
                info_card("Ng√†y ph√°t h√†nh (Issue_date)", d.strftime("%d/%m/%Y") if pd.notna(d) else "‚Äî")
                info_card("ƒê∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm tra (inspected_entity_name)", str(row.get("inspected_entity_name","‚Äî")))
                info_card("Ch·ª©c v·ª• (Signer_title)", str(row.get("signer_title","‚Äî")))
            with c3:
                info_card("Title", str(row.get("title","‚Äî")))
                info_card("Lƒ©nh v·ª±c (sector)", str(row.get("sector","‚Äî")))
            with c4:
                ps = row.get("period_start", pd.NaT); pe = row.get("period_end", pd.NaT)
                info_card("Th·ªùi gian b·∫Øt ƒë·∫ßu (period_start)", ps.strftime("%d/%m/%Y") if pd.notna(ps) else "‚Äî")
                info_card("Th·ªùi gian k·∫øt th√∫c (period_end)", pe.strftime("%d/%m/%Y") if pd.notna(pe) else "‚Äî")
            st.markdown("</div>", unsafe_allow_html=True)

# ---- Overalls ----
with tab_over:
    st.header("Th√¥ng Tin T·ªïng Quan")
    st.markdown("---")
    over_row = df_over.iloc[-1] if len(df_over) else pd.Series({})
    k1,k2,k3,k4,k5 = st.columns(5)
    with k1:
        st.metric("T·ªïng nh√¢n s·ª±", f"{int(over_row.get('staff_total', np.nan)) if pd.notna(over_row.get('staff_total', np.nan)) else '‚Äî'}")
        st.metric("M·∫´u ki·ªÉm tra", f"{int(over_row.get('sample_total_files', np.nan)) if pd.notna(over_row.get('sample_total_files', np.nan)) else '‚Äî'}")
    with k2:
        st.metric("Ph√≤ng nghi·ªáp v·ª• (HQ)", f"{int(over_row.get('departments_at_hq_count', np.nan)) if pd.notna(over_row.get('departments_at_hq_count', np.nan)) else '‚Äî'}")
        st.metric("Ph√≤ng giao d·ªãch", f"{int(over_row.get('transaction_offices_count', np.nan)) if pd.notna(over_row.get('transaction_offices_count', np.nan)) else '‚Äî'}")
    with k3:
        st.metric("Ngu·ªìn v·ªën g·∫ßn nh·∫•t", format_vnd(over_row.get("mobilized_capital_vnd", np.nan)))
    with k4:
        st.metric("D∆∞ n·ª£ g·∫ßn nh·∫•t", format_vnd(over_row.get("loans_outstanding_vnd", np.nan)))
    with k5:
        st.metric("N·ª£ x·∫•u g·∫ßn nh·∫•t", format_vnd(over_row.get("npl_total_vnd", np.nan)))
        st.metric("T·ª∑ l·ªá NPL / D∆∞ n·ª£", f"{over_row.get('npl_ratio_percent', np.nan):.2f}%" if pd.notna(over_row.get('npl_ratio_percent', np.nan)) else "‚Äî")
        st.metric("T·ªïng d∆∞ n·ª£ ƒë√£ ki·ªÉm tra", format_vnd(over_row.get("sample_outstanding_checked_vnd", np.nan)))

# ---- Findings ----
with tab_find:
    st.header("Ph√°t hi·ªán & Nguy√™n nh√¢n (Findings)")
    st.subheader(f"ƒêang l·ªçc theo: {len(selected_refs)}/{len(all_refs)} legal_reference")
    st.markdown("---")
    if f_df.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu theo b·ªô l·ªçc hi·ªán t·∫°i.")
    else:
        col1, col2 = st.columns(2)
        with col1:
            cat_count = f_df["category"].value_counts().reset_index()
            cat_count.columns = ["Category","Count"]
            fig1 = px.bar(cat_count, x="Category", y="Count", text="Count", color="Category",
                          title="S·ªë l·∫ßn xu·∫•t hi·ªán theo Category")
            fig1.update_traces(textposition="outside")
            fig1.update_layout(height=380, xaxis_title="", yaxis_title="S·ªë l·∫ßn")
            st.plotly_chart(fig1, use_container_width=True)
        with col2:
            cat_sub = f_df.groupby(["category","sub_category"]).size().reset_index(name="Count")
            fig2 = px.bar(cat_sub, x="category", y="Count", color="sub_category",
                          title="Category √ó Sub_category (s·ªë l·∫ßn)", barmode="group",
                          labels={"category":"Category","sub_category":"Sub_category","Count":"S·ªë l·∫ßn"})
            fig2.update_layout(height=380)
            st.plotly_chart(fig2, use_container_width=True)

        st.markdown("---")
        st.subheader("Xu h∆∞·ªõng theo Legal_reference (g·ªôp RAWx ‚Üí RAW)")
        legal_count = f_df["legal_reference_chart"].value_counts().reset_index()
        legal_count.columns = ["Legal_reference","Count"]
        fig3 = px.line(legal_count, x="Legal_reference", y="Count", markers=True,
                       title="S·ªë l·∫ßn xu·∫•t hi·ªán theo Legal_reference (g·ªôp RAWx‚ÜíRAW)")
        st.plotly_chart(fig3, use_container_width=True)
        st.info("RAW = lu·∫≠t/quy ƒë·ªãnh kh√¥ng ƒë∆∞·ª£c nh·∫Øc t·ªõi; √¥ tr·ªëng ƒë√£ g√°n RAW1, RAW2‚Ä¶ v√† g·ªôp th√†nh RAW cho bi·ªÉu ƒë·ªì.")

        st.markdown("---")
        st.subheader("T·∫ßn su·∫•t t·ª´ng Legal_reference (kh√¥ng g·ªôp ph·ª• l·ª•c/ƒëi·ªÉm kho·∫£n)")
        freq_tbl = f_df["legal_reference_filter"].value_counts().reset_index()
        freq_tbl.columns = ["Legal_reference","S·ªë l·∫ßn"]
        st.dataframe(freq_tbl, use_container_width=True, height=320)

        st.markdown("---")
        st.subheader("Chi ti·∫øt theo t·ª´ng Sub_category")
        order_sub = f_df["sub_category"].value_counts().index.tolist()
        for sub in order_sub:
            st.markdown(f"#### üîπ {sub}")
            sub_df = f_df[f_df["sub_category"]==sub].copy()
            sub_df["legal_reference"] = sub_df["legal_reference_filter"]  # ƒë·∫£m b·∫£o RAWx hi·ªÉn th·ªã tr·ª±c ti·∫øp
            cols_show = [c for c in ["description","legal_reference","quantified_amount","impacted_accounts","root_cause"] if c in sub_df.columns]
            sub_df = sub_df[cols_show]
            if "quantified_amount" in sub_df.columns:
                sub_df["quantified_amount"] = sub_df["quantified_amount"].apply(format_vnd)
            if "impacted_accounts" in sub_df.columns:
                sub_df["impacted_accounts"] = sub_df["impacted_accounts"].apply(lambda x: f"{int(x):,}" if pd.notna(x) else "‚Äî")
            rename = {
                "description":"M√¥ t·∫£",
                "legal_reference":"ƒêi·ªÅu lu·∫≠t/Quy ƒë·ªãnh",
                "quantified_amount":"S·ªë ti·ªÅn ·∫£nh h∆∞·ªüng",
                "impacted_accounts":"S·ªë KH/H·ªì s∆°",
                "root_cause":"Nguy√™n nh√¢n g·ªëc"
            }
            st.dataframe(sub_df.rename(columns=rename), use_container_width=True)

        st.markdown("---")
        st.subheader("Ph√¢n t√≠ch theo b·ªô lu·∫≠t")  # renamed
        # Show unique combos only (no counts / sums)
        tmp = f_df.copy()
        tmp["legal_reference"] = tmp["legal_reference_filter"]
        cols = ["legal_reference"]
        if "root_cause" in tmp.columns: cols.append("root_cause")
        if "recommendation" in tmp.columns: cols.append("recommendation")
        law_tbl = tmp[cols].drop_duplicates().reset_index(drop=True)
        law_tbl = law_tbl.rename(columns={
            "legal_reference":"Legal_reference",
            "root_cause":"Root_cause",
            "recommendation":"Recommendation"
        })
        st.dataframe(law_tbl, use_container_width=True)

# ---- Actions (show ALL rows, no filtering by findings) ----
with tab_act:
    st.header("Bi·ªán ph√°p kh·∫Øc ph·ª•c (Actions)")
    st.markdown("---")
    if df_act is None or df_act.empty:
        st.info("Kh√¥ng c√≥ sheet actions ho·∫∑c thi·∫øu c·ªôt. C·∫ßn: action_type, legal_reference, action_description, evidence_of_completion.")
    else:
        df_act_full = df_act.copy()
        df_act_full["Legal_reference"] = coalesce_series_with_raw(df_act_full["legal_reference"], prefix="RAW")
        # Chart
        if "action_type" in df_act_full.columns:
            act_count = df_act_full["action_type"].value_counts().reset_index()
            act_count.columns = ["Action_type","Count"]
            fig = px.pie(act_count, values="Count", names="Action_type", title="Ph√¢n lo·∫°i t√≠nh ch·∫•t bi·ªán ph√°p", hole=.35)
            fig.update_traces(textinfo="percent+label")
            st.plotly_chart(fig, use_container_width=True)
        st.markdown("---")
        # Table (all rows)
        cols = [c for c in ["Legal_reference","action_type","action_description","evidence_of_completion"] if c in df_act_full.columns or c=="Legal_reference"]
        rename = {
            "action_type":"T√≠nh ch·∫•t bi·ªán ph√°p",
            "action_description":"N·ªôi dung c√¥ng vi·ªác ph·∫£i l√†m",
            "evidence_of_completion":"C√¥ng vi·ªác chi ti·∫øt / Minh ch·ª©ng"
        }
        st.dataframe(df_act_full[cols].rename(columns=rename), use_container_width=True, height=500)

st.caption("¬© KLTT Dashboard ‚Ä¢ Streamlit ‚Ä¢ Altair ‚Ä¢ Plotly")


# ==============================
# GEMINI CHAT SIDEBAR LOGIC
# ==============================

def gemini_chat_sidebar(df_docs, df_over, df_find, df_act, f_df, no_data):
    """Th√™m khung chat Gemini v√†o sidebar."""
    st.header("ü§ñ Tr·ª£ l√Ω Gemini (Chat)")
    
    if "GEMINI_API_KEY" not in st.secrets:
        st.warning("Vui l√≤ng thi·∫øt l·∫≠p GEMINI_API_KEY trong file .streamlit/secrets.toml")
        return

    # Kh·ªüi t·∫°o client Gemini
    try:
        # S·ª≠ d·ª•ng genai.Client()
        client = genai.Client(api_key=st.secrets["AIzaSyB8kzqnUMxTiBT6oG-rLHo38fbJh6XKyVc"])
    except Exception as e:
        st.error(f"L·ªói kh·ªüi t·∫°o Gemini Client: {e}")
        return

    # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
    if "gemini_chat_history" not in st.session_state:
        # H·ªá th·ªëng prompt ban ƒë·∫ßu ƒë·ªÉ cung c·∫•p ng·ªØ c·∫£nh v·ªÅ ·ª©ng d·ª•ng
        initial_prompt = (
            "B·∫°n l√† m·ªôt tr·ª£ l√Ω ph√¢n t√≠ch d·ªØ li·ªáu chuy√™n nghi·ªáp, am hi·ªÉu v·ªÅ c√°c K·∫øt lu·∫≠n Thanh tra (KLTT). "
            "Ng∆∞·ªùi d√πng ƒëang xem Dashboard KLTT. "
            "H√£y tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn ph√¢n t√≠ch d·ªØ li·ªáu, √Ω nghƒ©a c·ªßa c√°c ch·ªâ s·ªë (n·∫øu c√≥ d·ªØ li·ªáu) ho·∫∑c t∆∞ v·∫•n v·ªÅ c√°ch s·ª≠ d·ª•ng dashboard. "
            "H·∫°n ch·∫ø ƒë∆∞a ra c√°c c√¢u tr·∫£ l·ªùi qu√° d√†i. N·∫øu kh√¥ng bi·∫øt, h√£y n√≥i r√µ b·∫°n kh√¥ng c√≥ th√¥ng tin."
        )
        # S·ª≠ d·ª•ng m√¥ h√¨nh gemini-2.5-flash cho t·ªëc ƒë·ªô v√† hi·ªáu su·∫•t t·ªët trong h·ªôi tho·∫°i
        st.session_state.gemini_chat_history = client.chats.create(
            model="gemini-2.5-flash",
            system_instruction=initial_prompt
        )

    chat = st.session_state.gemini_chat_history

    # Th√™m th√¥ng tin ng·ªØ c·∫£nh d·ªØ li·ªáu hi·ªán t·∫°i v√†o l·ªãch s·ª≠ chat (nh∆∞ng kh√¥ng hi·ªÉn th·ªã)
    # Cung c·∫•p cho m√¥ h√¨nh c√°c DataFrame d∆∞·ªõi d·∫°ng t√≥m t·∫Øt ho·∫∑c chu·ªói
    context_data = ""
    if not no_data and not df_find.empty:
        # Ch·ªâ t√≠nh t·ªïng n·∫øu c·ªôt t·ªìn t·∫°i v√† kh√¥ng r·ªóng
        npl_total = df_over['npl_total_vnd'].sum() if 'npl_total_vnd' in df_over.columns and not df_over.empty else np.nan
        quantified_amount = f_df['quantified_amount'].sum() if 'quantified_amount' in f_df.columns and not f_df.empty else np.nan
        
        context_data = (
            "NG·ªÆ C·∫¢NH D·ªÆ LI·ªÜU HI·ªÜN T·∫†I (T√≥m t·∫Øt DataFrames ƒë√£ t·∫£i):\n"
            f"1. Documents: {len(df_docs)} b√°o c√°o, c√°c c·ªôt: {list(df_docs.columns)}\n"
            f"2. Overalls: {len(df_over)} h√†ng, T·ªïng N·ª£ x·∫•u: {format_vnd(npl_total)}\n"
            f"3. Findings (ƒë√£ l·ªçc): {len(f_df)} ph√°t hi·ªán, T·ªïng ti·ªÅn ·∫£nh h∆∞·ªüng: {format_vnd(quantified_amount)}, "
            f"C√°c Category ch√≠nh: {f_df['category'].dropna().unique().tolist() if 'category' in f_df.columns and not f_df.empty else []}\n"
            f"4. Actions: {len(df_act)} bi·ªán ph√°p (n·∫øu c√≥).\n"
            "H√£y s·ª≠ d·ª•ng th√¥ng tin n√†y ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c h∆°n v·ªÅ d·ªØ li·ªáu.\n"
        )
    else:
        context_data = "KH√îNG C√ì D·ªÆ LI·ªÜU ƒê∆Ø·ª¢C T·∫¢I. Ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi chung v·ªÅ Dashboard."

    # L·∫•y l·ªãch s·ª≠ tin nh·∫Øn t·ª´ session state (lo·∫°i b·ªè tin nh·∫Øn h·ªá th·ªëng)
    # L·∫•y l·ªãch s·ª≠ chat t·ª´ ƒë·ªëi t∆∞·ª£ng chat hi·ªán t·∫°i
    display_messages = [
        {"role": msg.role, "content": msg.parts[0].text} 
        for msg in chat.get_history() 
        if msg.role in ["user", "model"]
    ]

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for message in display_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # X·ª≠ l√Ω input ng∆∞·ªùi d√πng
    user_prompt = st.chat_input("H·ªèi Gemini v·ªÅ dashboard ho·∫∑c d·ªØ li·ªáu...", key="gemini_chat_input")

    if user_prompt:
        # Th√™m prompt ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ v√† hi·ªÉn th·ªã ngay l·∫≠p t·ª©c
        with st.chat_message("user"):
            st.markdown(user_prompt)

        # K·∫øt h·ª£p ng·ªØ c·∫£nh d·ªØ li·ªáu v√†o prompt th·ª±c g·ª≠i ƒëi
        full_prompt = context_data + "\n" + user_prompt

        # G·ªçi API Gemini
        with st.chat_message("assistant"):
            with st.spinner("Gemini ƒëang suy nghƒ©..."):
                try:
                    # G·ª≠i tin nh·∫Øn ƒë·∫øn m√¥ h√¨nh chat
                    response = chat.send_message(full_prompt)
                    st.markdown(response.text)
                except Exception as e:
                    st.error(f"L·ªói khi g·ªçi Gemini API: {e}. Vui l√≤ng ki·ªÉm tra API Key v√† quy·ªÅn truy c·∫≠p.")
